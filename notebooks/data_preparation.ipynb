{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265022d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Coletando POIs para Quedas de Calandula (Malanje)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_quedas_de_calandula.geojson\n",
      "\n",
      " Coletando POIs para Miradouro da Lua (Luanda)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_miradouro_da_lua.geojson\n",
      "\n",
      " Coletando POIs para Museu Kulumbimbi (Zaire)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_museu_kulumbimbi.geojson\n",
      "\n",
      " Coletando POIs para Reserva Parcial do Namibe (Namibe)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_reserva_parcial_do_namibe.geojson\n",
      "\n",
      " Coletando POIs para Fortaleza de São Miguel (Luanda)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_fortaleza_de_são_miguel.geojson\n",
      "\n",
      " Coletando POIs para Ilha do Mussulo (Luanda)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_ilha_do_mussulo.geojson\n",
      "\n",
      " Coletando POIs para Cânion do Rio Kalandula (Malanje)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_cânion_do_rio_kalandula.geojson\n",
      "\n",
      " Coletando POIs para Parque Nacional da Quiçama (Luanda)...\n",
      " Erro na coleta: No matching features. Check query location, tags, and log.\n",
      " Nenhum POI encontrado em Parque Nacional da Quiçama.\n",
      "\n",
      " Coletando POIs para Cristo Rei (Huambo)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_cristo_rei.geojson\n",
      "\n",
      " Coletando POIs para Serra da Leba (Huíla)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_serra_da_leba.geojson\n",
      "\n",
      " Coletando POIs para Fenda da Tundavala (Huíla)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_fenda_da_tundavala.geojson\n",
      "\n",
      " Coletando POIs para Baía Azul (Benguela)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_baía_azul.geojson\n",
      "\n",
      " Coletando POIs para Quedas do Rio Chiumbe (Moxico)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_quedas_do_rio_chiumbe.geojson\n",
      "\n",
      " Coletando POIs para Parque Nacional de Cameia (Moxico)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_parque_nacional_de_cameia.geojson\n",
      "\n",
      " Coletando POIs para Grutas do Nzenzo (Uíge)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_grutas_do_nzenzo.geojson\n",
      "\n",
      " Arquivo combinado salvo em: ..\\data\\geoespacial\\pontos_turisticos_angola_raw.geojson\n"
     ]
    }
   ],
   "source": [
    "# carregar dataset rudementar\n",
    "# ==============================================================\n",
    "# CARREGAR DATASET RUDIMENTAR — Coleta de POIs do OSM\n",
    "# Angola (Pontos Turísticos com coordenadas conhecidas)\n",
    "# ==============================================================\n",
    "\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# === Diretório de saída ===\n",
    "DATA_DIR = Path(\"../data/geoespacial\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Locais turísticos (com coordenadas conhecidas) ===\n",
    "locais_turisticos = [\n",
    "    {\"nome\": \"Quedas de Calandula\", \"lat\": -9.075025, \"lon\": 16.001131, \"provincia\": \"Malanje\"},\n",
    "    {\"nome\": \"Miradouro da Lua\", \"lat\": -9.221147, \"lon\": 13.090001, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Museu Kulumbimbi\", \"lat\": -6.264389, \"lon\": 14.245581, \"provincia\": \"Zaire\"},\n",
    "    {\"nome\": \"Reserva Parcial do Namibe\", \"lat\": -15.766760, \"lon\": 12.399914, \"provincia\": \"Namibe\"},\n",
    "    {\"nome\": \"Fortaleza de São Miguel\", \"lat\": -8.808343416048587, \"lon\": 13.223444621289627, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Ilha do Mussulo\", \"lat\": -8.964635, \"lon\":13.050462, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Cânion do Rio Kalandula\", \"lat\": -9.074959, \"lon\": 16.001378, \"provincia\": \"Malanje\"},\n",
    "    {\"nome\": \"Parque Nacional da Quiçama\", \"lat\": -9.750007, \"lon\": 13.583333, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Cristo Rei\", \"lat\": -14.940039, \"lon\": 13.511860, \"provincia\": \"Huambo\"},\n",
    "    {\"nome\": \"Serra da Leba\", \"lat\": -15.0788, \"lon\": 13.2397, \"provincia\": \"Huíla\"},\n",
    "    {\"nome\": \"Fenda da Tundavala\", \"lat\": -14.817465, \"lon\": 13.381539, \"provincia\": \"Huíla\"},\n",
    "    {\"nome\": \"Baía Azul\", \"lat\": -12.627978, \"lon\": 13.234185, \"provincia\": \"Benguela\"},\n",
    "    {\"nome\": \"Quedas do Rio Chiumbe\", \"lat\": -11.021380, \"lon\": 20.203180, \"provincia\": \"Moxico\"},\n",
    "    {\"nome\": \"Parque Nacional de Cameia\", \"lat\": -11.883338, \"lon\": 21.666681, \"provincia\": \"Moxico\"},\n",
    "    {\"nome\": \"Grutas do Nzenzo\", \"lat\": -7.520192, \"lon\":14.565103, \"provincia\": \"Uíge\"}\n",
    "]\n",
    "\n",
    "BUFFER_RADIUS = 5000  # 5 km\n",
    "dfs = []\n",
    "\n",
    "# === Tags OSM — Turismo + Infraestrutura ===\n",
    "TAGS = {\n",
    "    \"tourism\": True,\n",
    "    \"amenity\": True,\n",
    "    \"leisure\": True,\n",
    "    \"natural\": True,\n",
    "    \"landuse\": True,\n",
    "    \"highway\": True,\n",
    "    \"waterway\": True,\n",
    "    \"power\": True,\n",
    "    \"man_made\": True,\n",
    "    \"railway\": True,\n",
    "    \"building\": True\n",
    "}\n",
    "\n",
    "\n",
    "def coletar_pois(lat, lon, tags, buffer_m):\n",
    "    \"\"\"Retorna os POIs dentro do raio (buffer_m) ao redor das coordenadas.\"\"\"\n",
    "    try:\n",
    "        gdf_ponto = gpd.GeoDataFrame([[\"ponto\", Point(lon, lat)]],\n",
    "                                     columns=[\"nome\", \"geometry\"],\n",
    "                                     crs=\"EPSG:4326\")\n",
    "        area_busca = gdf_ponto.to_crs(3857).buffer(buffer_m).to_crs(4326).iloc[0]\n",
    "\n",
    "        pois = ox.features_from_polygon(area_busca, tags).reset_index()\n",
    "        if pois.empty:\n",
    "            return None\n",
    "\n",
    "        # Garantir colunas\n",
    "        colunas_necessarias = [\n",
    "            \"osm_id\", \"name\", \"tourism\", \"amenity\", \"leisure\",\n",
    "            \"natural\", \"landuse\", \"highway\", \"waterway\",\n",
    "            \"power\", \"man_made\", \"railway\", \"building\", \"geometry\"\n",
    "        ]\n",
    "        for c in colunas_necessarias:\n",
    "            if c not in pois.columns:\n",
    "                pois[c] = None\n",
    "        return pois[colunas_necessarias]\n",
    "    except Exception as e:\n",
    "        print(f\" Erro na coleta: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# === Loop pelos locais ===\n",
    "for item in locais_turisticos:\n",
    "    nome = item[\"nome\"]\n",
    "    lat = item[\"lat\"]\n",
    "    lon = item[\"lon\"]\n",
    "    prov = item[\"provincia\"]\n",
    "\n",
    "    print(f\"\\n Coletando POIs para {nome} ({prov})...\")\n",
    "\n",
    "    pois = coletar_pois(lat, lon, TAGS, BUFFER_RADIUS)\n",
    "\n",
    "    if pois is not None:\n",
    "        # Adicionar metadados\n",
    "        pois[\"ponto_turistico\"] = nome\n",
    "        pois[\"provincia\"] = prov\n",
    "        pois[\"fonte_dados\"] = \"OpenStreetMap\"\n",
    "        pois[\"latitude\"] = pois.to_crs(3857).geometry.centroid.to_crs(4326).y\n",
    "        pois[\"longitude\"] = pois.to_crs(3857).geometry.centroid.to_crs(4326).x\n",
    "\n",
    "        # Salvar individualmente\n",
    "        output_path = DATA_DIR / f\"pois_{nome.replace(' ', '_').lower()}.geojson\"\n",
    "        pois.to_file(output_path, driver=\"GeoJSON\")\n",
    "        print(f\"    Salvo: {output_path}\")\n",
    "\n",
    "        dfs.append(pois)\n",
    "    else:\n",
    "        print(f\" Nenhum POI encontrado em {nome}.\")\n",
    "\n",
    "    time.sleep(1.5)  # respeitar limite de requisições\n",
    "\n",
    "# === Combinar tudo ===\n",
    "if dfs:\n",
    "    pois_final = gpd.GeoDataFrame(pd.concat(dfs, ignore_index=True), crs=\"EPSG:4326\")\n",
    "    output_final = DATA_DIR / \"pontos_turisticos_angola_raw.geojson\"\n",
    "    pois_final.to_file(output_final, driver=\"GeoJSON\")\n",
    "    print(f\"\\n Arquivo combinado salvo em: {output_final}\")\n",
    "else:\n",
    "    print(\"\\n Nenhum POI foi coletado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96df2665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados normalizados salvos em: ..\\data\\geoespacial\\pontos_turisticos_angola_normalizado.geojson\n"
     ]
    }
   ],
   "source": [
    "# Normalizar \n",
    "\n",
    "# ==============================================================\n",
    "# NORMALIZAÇÃO DOS DADOS GEOFÍSICOS E DE INFRAESTRUTURA\n",
    "# ==============================================================\n",
    "\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data/geoespacial\")\n",
    "input_path = DATA_DIR / \"pontos_turisticos_angola_raw.geojson\"\n",
    "output_path = DATA_DIR / \"pontos_turisticos_angola_normalizado.geojson\"\n",
    "\n",
    "# ===  Carregar dados brutos ===\n",
    "pois = gpd.read_file(input_path)\n",
    "\n",
    "# ===  Limpeza básica ===\n",
    "if \"osm_id\" in pois.columns:\n",
    "    pois = pois.drop_duplicates(subset=[\"osm_id\"], keep=\"first\")\n",
    "else:\n",
    "    pois = pois.drop_duplicates(subset=[\"name\", \"geometry\"], keep=\"first\")\n",
    "\n",
    "pois = pois[pois.is_valid]\n",
    "pois = pois.dropna(subset=[\"geometry\"])\n",
    "\n",
    "# ===  Garantir colunas críticas ===\n",
    "for col in [\"name\", \"tourism\", \"amenity\", \"leisure\", \"natural\", \"landuse\", \n",
    "            \"highway\", \"power\", \"latitude\", \"longitude\"]:\n",
    "    if col not in pois.columns:\n",
    "        pois[col] = None\n",
    "\n",
    "# ===  Correção e normalização ===\n",
    "pois[\"name\"] = pois[\"name\"].fillna(\"Desconhecido\").astype(str)\n",
    "\n",
    "map_tourism = {\n",
    "    \"guest_house\": \"accommodation\",\n",
    "    \"hotel\": \"accommodation\",\n",
    "    \"motel\": \"accommodation\",\n",
    "    \"museum\": \"culture\",\n",
    "    \"attraction\": \"attraction\"\n",
    "}\n",
    "map_amenity = {\n",
    "    \"restaurant\": \"food_service\",\n",
    "    \"fast_food\": \"food_service\",\n",
    "    \"hospital\": \"health\",\n",
    "    \"school\": \"education\"\n",
    "}\n",
    "\n",
    "pois[\"tourism\"] = pois[\"tourism\"].replace(map_tourism)\n",
    "pois[\"amenity\"] = pois[\"amenity\"].replace(map_amenity)\n",
    "\n",
    "# ===  Variáveis derivadas ===\n",
    "pois[\"is_touristic\"] = pois[\"tourism\"].notna().astype(int)\n",
    "pois[\"is_infrastructure\"] = pois[[\"amenity\", \"highway\", \"power\"]].notna().any(axis=1).astype(int)\n",
    "\n",
    "# ===  Salvar resultado ===\n",
    "pois.to_file(output_path, driver=\"GeoJSON\")\n",
    "print(f\" Dados normalizados salvos em: {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36bcbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dados de mobilidade normalizados salvos em: ..\\data\\climatic-environmental\\mobilidade_infra_normalizado.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# NORMALIZAÇÃO DOS DADOS DE MOBILIDADE E DE INFRAESTRUTURA\n",
    "# ==============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Diretório e arquivo ===\n",
    "DATA_DIR = Path(\"../data/climatic-environmental\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "input_path = DATA_DIR / \"mobilidade_infra.csv\"\n",
    "\n",
    "# === Carregar ===\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# === Normalizar nomes de colunas ===\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(r'\\s+', '_', regex=True)\n",
    "\n",
    "# === Preenchimento básico ===\n",
    "num_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "for c in num_cols:\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].fillna(\"desconhecido\")\n",
    "\n",
    "# === Limites plausíveis ===\n",
    "if \"velocidade_media_kmh\" in df.columns:\n",
    "    df[\"velocidade_media_kmh\"] = df[\"velocidade_media_kmh\"].clip(lower=0, upper=200)\n",
    "\n",
    "if \"capacidade\" in df.columns:\n",
    "    df[\"capacidade\"] = df[\"capacidade\"].clip(lower=0)\n",
    "\n",
    "if \"fluxo_diario\" in df.columns:\n",
    "    df[\"fluxo_diario\"] = df[\"fluxo_diario\"].clip(lower=0)\n",
    "\n",
    "# === Datas ===\n",
    "for date_col in [\"date\", \"data\", \"timestamp\"]:\n",
    "    if date_col in df.columns:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "\n",
    "# === Normalizar categorias de infraestrutura ===\n",
    "infra_col_candidates = [c for c in df.columns if c in (\"tipo\", \"tipo_infra\", \"infra_type\", \"category\")]\n",
    "if infra_col_candidates:\n",
    "    infra_col = infra_col_candidates[0]\n",
    "    df[infra_col] = df[infra_col].astype(str).str.lower()\n",
    "    df[\"is_road\"] = df[infra_col].str.contains(r\"road|highway|estrada\", na=False).astype(int)\n",
    "    df[\"is_rail\"] = df[infra_col].str.contains(r\"rail|ferrovia\", na=False).astype(int)\n",
    "    df[\"is_port\"] = df[infra_col].str.contains(r\"port|porto\", na=False).astype(int)\n",
    "    df[\"is_airport\"] = df[infra_col].str.contains(r\"airport|aeroporto\", na=False).astype(int)\n",
    "\n",
    "# === Coordenadas -> GeoDataFrame ===\n",
    "lat_candidates = [c for c in df.columns if c in (\"latitude\", \"lat\", \"y\")]\n",
    "lon_candidates = [c for c in df.columns if c in (\"longitude\", \"lon\", \"lng\", \"x\")]\n",
    "\n",
    "output_csv = DATA_DIR / \"mobilidade_infra_normalizado.csv\"\n",
    "output_geo = DATA_DIR / \"mobilidade_infra_normalizado.geojson\"\n",
    "\n",
    "if lat_candidates and lon_candidates:\n",
    "    lat_col = lat_candidates[0]\n",
    "    lon_col = lon_candidates[0]\n",
    "    df = df.dropna(subset=[lat_col, lon_col])\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df.copy(),\n",
    "        geometry=gpd.points_from_xy(df[lon_col].astype(float), df[lat_col].astype(float)),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    gdf.to_file(output_geo, driver=\"GeoJSON\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Dados de mobilidade normalizados salvos em:\\n   - {output_csv}\\n   - {output_geo}\")\n",
    "else:\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Dados de mobilidade normalizados salvos em: {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c491642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados climáticos-ambientais normalizados salvos em: ..\\data\\climatic-environmental\\clima_lulc_normalizado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ==============================================================\n",
    "# NORMALIZAÇÃO DOS DADOS CLIMATICOS-AMBIENTAIS\n",
    "\n",
    "# ==============================================================\n",
    "# === Diretório e arquivos ===\n",
    "DATA_DIR = Path(\"../data/climatic-environmental\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "input_clima = DATA_DIR / \"exemplo.csv\"\n",
    "df_clima = pd.read_csv(input_clima)\n",
    "\n",
    "# === Normalização dos dados ===\n",
    "# Temperatura média anual (°C)\n",
    "df_clima['temp_med_anual'] = df_clima['temp_med_anual'].clip(20, 35)\n",
    "\n",
    "# Precipitação anual (mm)\n",
    "df_clima['precipitacao_anual'] = df_clima['precipitacao_anual'].clip(0, 2000)\n",
    "\n",
    "# Índices de vegetação e água\n",
    "for col in ['NDVI', 'EVI', 'NDWI']:\n",
    "    df_clima[col] = df_clima[col].clip(-1, 1)\n",
    "\n",
    "# Códigos LULC (Land Use Land Cover)\n",
    "df_clima['LULC_codigo'] = df_clima['LULC_codigo'].astype('category')\n",
    "\n",
    "# Altitude (m)\n",
    "df_clima['altitude'] = df_clima['altitude'].clip(0, 2500)\n",
    "\n",
    "# === Salvar dados normalizados ===\n",
    "output_path = DATA_DIR / \"clima_lulc_normalizado.csv\"\n",
    "df_clima.to_csv(output_path, index=False)\n",
    "print(f\" Dados climáticos-ambientais normalizados salvos em: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f57fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados econômicos-sociais normalizados salvos em: ..\\data\\economicsocial\\economicsocial_normalizado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ==============================================================\n",
    "# NORMALIZAÇÃO DOS DADOS ECONÔMICOS-SOCIAIS\n",
    "# ==============================================================\n",
    "# === Diretório e arquivos ===\n",
    "DATA_DIR = Path(\"../data/economicsocial\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "input_eco = DATA_DIR / \"dados_socioeconomicos.csv\"\n",
    "df_eco = pd.read_csv(input_eco)\n",
    "\n",
    "# === Normalização dos dados ===\n",
    "# PIB per capita (USD)\n",
    "df_eco['pib_per_capita'] = df_eco['pib_per_capita'].clip(500, 5000)\n",
    "\n",
    "# População\n",
    "df_eco['populacao'] = df_eco['populacao'].clip(1000, 1000000)\n",
    "\n",
    "# Índice de desenvolvimento humano\n",
    "df_eco['idh'] = df_eco['idh'].clip(0, 1)\n",
    "\n",
    "# Densidade populacional (hab/km²)\n",
    "df_eco['densidade_pop'] = df_eco['densidade_pop'].clip(0, 1000)\n",
    "\n",
    "# Taxa de urbanização (%)\n",
    "df_eco['taxa_urbanizacao'] = df_eco['taxa_urbanizacao'].clip(0, 100)\n",
    "\n",
    "# === Salvar dados normalizados ===\n",
    "output_path = DATA_DIR / \"economicsocial_normalizado.csv\"\n",
    "df_eco.to_csv(output_path, index=False)\n",
    "print(f\" Dados econômicos-sociais normalizados salvos em: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b056fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Variáveis espaciais geradas e salvas em: ..\\data\\geoespacial\\pontos_turisticos_angola_raw.geojson\n"
     ]
    }
   ],
   "source": [
    "# Gerar variáveis espaciais \n",
    "# ============================================================== \n",
    "# GERAR VARIÁVEIS ESPACIAIS\n",
    "# ==============================================================\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = Path(\"../data/geoespacial\")\n",
    "input_path = DATA_DIR / \"pontos_turisticos_angola_normalizado.geojson\"\n",
    "output_path = DATA_DIR / \"pontos_turisticos_angola_raw.geojson\"\n",
    "\n",
    "# === Carregar dados normalizados ===\n",
    "pois = gpd.read_file(input_path)\n",
    "\n",
    "# === Converter para projeção métrica (metros) para cálculos espaciais ===\n",
    "pois = pois.to_crs(epsg=3857)\n",
    "\n",
    "# === Exemplo 1: Calcular centroid de cada ponto turístico (se houver polígonos) ===\n",
    "# (No caso de pontos simples, é só o próprio ponto)\n",
    "pois['centroid_x'] = pois.geometry.centroid.x\n",
    "pois['centroid_y'] = pois.geometry.centroid.y\n",
    "\n",
    "# === Exemplo 2: Distância até o ponto turístico mais próximo ===\n",
    "# Criar uma função para calcular a menor distância entre cada ponto\n",
    "def nearest_distance(point, others):\n",
    "    # Retorna a menor distância (em metros) até outro ponto\n",
    "    distances = others.geometry.distance(point)\n",
    "    distances = distances[distances > 0]  # ignora distância zero (o próprio ponto)\n",
    "    if len(distances) > 0:\n",
    "        return distances.min()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "pois['dist_to_nearest_poi'] = pois.geometry.apply(lambda p: nearest_distance(p, pois))\n",
    "\n",
    "# === Exemplo 3: Buffer / contagem de POIs próximos (densidade) ===\n",
    "BUFFER_RADIUS = 1000  # metros\n",
    "pois['pois_within_1km'] = pois.geometry.apply(lambda g: pois[pois.geometry.within(g.buffer(BUFFER_RADIUS))].shape[0] - 1) \n",
    "# -1 para excluir o próprio ponto\n",
    "\n",
    "# === Exemplo 4: Flag de proximidade a categorias específicas ===\n",
    "# Por exemplo, se existe hospital ou escola em 1km\n",
    "def has_category_nearby(point, category_col, category_value, radius=1000):\n",
    "    buffer = point.buffer(radius)\n",
    "    subset = pois[(pois[category_col] == category_value) & (pois.geometry.within(buffer))]\n",
    "    return int(len(subset) > 0)\n",
    "\n",
    "pois['hospital_nearby'] = pois.geometry.apply(lambda g: has_category_nearby(g, 'amenity', 'hospital'))\n",
    "pois['school_nearby'] = pois.geometry.apply(lambda g: has_category_nearby(g, 'amenity', 'school'))\n",
    "\n",
    "# === Salvar dataset com variáveis espaciais ===\n",
    "pois = pois.to_crs(epsg=4326)  # voltar para lat/lon\n",
    "pois.to_file(output_path, driver=\"GeoJSON\")\n",
    "print(f\" Variáveis espaciais geradas e salvas em: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6845c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Carregando camadas de dados...\n",
      "🔹 Normalizando nomes e criando chaves...\n",
      "🔹 Realizando junção semântica (clima + socioeconômico + mobilidade)...\n",
      "🔹 Realizando junção espacial com dados geográficos...\n",
      " Salvando arquivos em: ..\\data\\integrado\n",
      " Integração concluída com sucesso!\n",
      " Arquivos gerados:\n",
      " - dataset_integrado.csv\n",
      " - dataset_integrado.geojson\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# ============================================================\n",
    "# 🔹 FUNÇÕES AUXILIARES\n",
    "# ============================================================\n",
    "\n",
    "def normalizar(texto):\n",
    "    \"\"\"Remove acentos, espaços extras e converte em minúsculas.\"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    texto = str(texto).strip().lower()\n",
    "    texto = re.sub(r\"[áàãâä]\", \"a\", texto)\n",
    "    texto = re.sub(r\"[éèêë]\", \"e\", texto)\n",
    "    texto = re.sub(r\"[íìîï]\", \"i\", texto)\n",
    "    texto = re.sub(r\"[óòõôö]\", \"o\", texto)\n",
    "    texto = re.sub(r\"[úùûü]\", \"u\", texto)\n",
    "    texto = re.sub(r\"ç\", \"c\", texto)\n",
    "    texto = re.sub(r\"[^a-z0-9 ]\", \"\", texto)\n",
    "    return texto\n",
    "\n",
    "\n",
    "def carregar_csv(caminho):\n",
    "    \"\"\"Lê CSV corrigindo encoding e normalizando nomes de colunas.\"\"\"\n",
    "    df = pd.read_csv(caminho, encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "    df.columns = [normalizar(c) for c in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def adicionar_chave(df, colunas_possiveis):\n",
    "    \"\"\"Adiciona coluna 'key' com nome normalizado.\"\"\"\n",
    "    for col in df.columns:\n",
    "        if any(col.startswith(c) for c in colunas_possiveis):\n",
    "            df[\"key\"] = df[col].astype(str).apply(normalizar)\n",
    "            return df\n",
    "    raise ValueError(f\"❌ Nenhuma coluna de nome encontrada. Colunas disponíveis: {list(df.columns)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 🔹 CAMINHOS DOS DADOS\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = Path(\"../data\")\n",
    "PATH_GEO_NORM = BASE_DIR / \"geoespacial/pontos_turisticos_angola_normalizado.geojson\"\n",
    "PATH_GEO_RAW = BASE_DIR / \"geoespacial/pontos_turisticos_angola_raw.geojson\"\n",
    "PATH_CLIMA = BASE_DIR / \"climatic-environmental/clima_lulc_normalizado.csv\"\n",
    "PATH_MOB = BASE_DIR / \"climatic-environmental/mobilidade_infra_normalizado.csv\"\n",
    "PATH_SOCIO = BASE_DIR / \"economicsocial/economicsocial_normalizado.csv\"\n",
    "\n",
    "# ============================================================\n",
    "# 🔹 CARREGAR CAMADAS\n",
    "# ============================================================\n",
    "\n",
    "print(\"🔹 Carregando camadas de dados...\")\n",
    "\n",
    "gdf_norm = gpd.read_file(PATH_GEO_NORM)\n",
    "gdf_raw = gpd.read_file(PATH_GEO_RAW)\n",
    "df_clima = carregar_csv(PATH_CLIMA)\n",
    "df_mob = carregar_csv(PATH_MOB)\n",
    "df_socio = carregar_csv(PATH_SOCIO)\n",
    "\n",
    "# ============================================================\n",
    "# 🔹 ADICIONAR CHAVES NORMALIZADAS\n",
    "# ============================================================\n",
    "\n",
    "print(\"🔹 Normalizando nomes e criando chaves...\")\n",
    "\n",
    "gdf_norm = adicionar_chave(gdf_norm, [\"ponto_turistico\", \"name\", \"nome\"])\n",
    "gdf_raw = adicionar_chave(gdf_raw, [\"ponto_turistico\", \"name\", \"nome\"])\n",
    "df_clima = adicionar_chave(df_clima, [\"nome_ponto_turistico\", \"nome\"])\n",
    "df_mob = adicionar_chave(df_mob, [\"nome\"])\n",
    "df_socio = adicionar_chave(df_socio, [\"nome\"])\n",
    "\n",
    "# ============================================================\n",
    "# 🔹 JUNÇÃO SEMÂNTICA — CLIMA + SOCIO + MOBILIDADE\n",
    "# ============================================================\n",
    "\n",
    "print(\"🔹 Realizando junção semântica (clima + socioeconômico + mobilidade)...\")\n",
    "\n",
    "df_semantico = df_clima.merge(df_socio, on=\"key\", how=\"outer\", suffixes=(\"_clima\", \"_socio\"))\n",
    "df_semantico = df_semantico.merge(df_mob, on=\"key\", how=\"outer\", suffixes=(\"\", \"_mob\"))\n",
    "\n",
    "# ============================================================\n",
    "# 🔹 JUNÇÃO ESPACIAL — COM GEOESPACIAL NORMALIZADO E RAW\n",
    "# ============================================================\n",
    "\n",
    "print(\"🔹 Realizando junção espacial com dados geográficos...\")\n",
    "\n",
    "# Converter para GeoDataFrame com base em coordenadas (lat/lon)\n",
    "if \"longitude\" in gdf_norm.columns and \"latitude\" in gdf_norm.columns:\n",
    "    gdf_norm[\"geometry\"] = gdf_norm.apply(lambda x: Point(x[\"longitude\"], x[\"latitude\"]), axis=1)\n",
    "gdf_norm = gpd.GeoDataFrame(gdf_norm, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Merge final com base na chave\n",
    "gdf_final = gdf_norm.merge(df_semantico, on=\"key\", how=\"left\")\n",
    "gdf_final = gdf_final.merge(gdf_raw.drop(columns=[\"geometry\"]), on=\"key\", how=\"left\", suffixes=(\"\", \"_raw\"))\n",
    "\n",
    "# ============================================================\n",
    "# 🔹 EXPORTAR RESULTADOS\n",
    "# ============================================================\n",
    "\n",
    "OUTPUT_DIR = BASE_DIR / \"integrado\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_out = OUTPUT_DIR / \"dataset_integrado.csv\"\n",
    "geojson_out = OUTPUT_DIR / \"dataset_integrado.geojson\"\n",
    "\n",
    "print(f\" Salvando arquivos em: {OUTPUT_DIR}\")\n",
    "gdf_final.to_csv(csv_out, index=False, encoding=\"utf-8\")\n",
    "gdf_final.to_file(geojson_out, driver=\"GeoJSON\")\n",
    "\n",
    "print(\" Integração concluída com sucesso!\")\n",
    "print(f\" Arquivos gerados:\\n - {csv_out.name}\\n - {geojson_out.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae13a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Input salvo em: ..\\data\\model_input.csv\n",
      "  nome_ponto_turistico_clima provincia_clima  lat_clima  lon_clima  \\\n",
      "0        Quedas de Calandula         Malanje  -9.075025  16.001131   \n",
      "1           Miradouro da Lua          Luanda  -9.221147  13.090001   \n",
      "2           Museu Kulumbimbi           Zaire  -6.264389  14.245581   \n",
      "3  Reserva Parcial do Namibe          Namibe -15.766760  12.399914   \n",
      "4    Fortaleza de São Miguel          Luanda  -8.808343  13.223445   \n",
      "\n",
      "   temp_med_anual  precipitacao_anual  ndvi   evi  ndwi  altitude  populacao  \\\n",
      "0            28.8               218.9  0.80  0.16  0.02     287.0      95533   \n",
      "1            24.8               304.1  0.77  0.68  0.08    1148.0      52641   \n",
      "2            27.8               343.0  0.20  0.46  0.08     683.0      54008   \n",
      "3            24.3               286.7  0.15  0.60  0.04     362.0     166079   \n",
      "4            28.1               158.6  0.62  0.47  0.16    1192.0     192436   \n",
      "\n",
      "   densidade_pop  pib_per_capita    idh  taxa_urbanizacao  emprego_turismo  \\\n",
      "0          412.4         4015.12  0.543              50.1             14.0   \n",
      "1          422.9         2765.22  0.590              69.3             13.1   \n",
      "2          151.1         1998.99  0.726              41.5             12.5   \n",
      "3          200.8         1815.76  0.624              44.9              7.5   \n",
      "4          250.0         3426.64  0.678              70.6              8.8   \n",
      "\n",
      "   distancia_estrada_principal_km  distancia_cidade_km  \n",
      "0                             2.7                157.6  \n",
      "1                             1.4                 11.0  \n",
      "2                             6.0                 38.5  \n",
      "3                             6.6                106.4  \n",
      "4                             4.3                129.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# =====================================================\n",
    "#  Gerar model_input.csv consolidado e pronto p/ ML\n",
    "# =====================================================\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "DATA_CLIMA = Path(\"../data/climatic-environmental/clima_lulc_normalizado.csv\")\n",
    "DATA_MOB = Path(\"../data/climatic-environmental/mobilidade_infra_normalizado.csv\")\n",
    "DATA_SOCIO = Path(\"../data/economicsocial/economicsocial_normalizado.csv\")\n",
    "\n",
    "# === 1. Carregar dados ===\n",
    "df_clima = pd.read_csv(DATA_CLIMA)\n",
    "df_mob = pd.read_csv(DATA_MOB)\n",
    "df_socio = pd.read_csv(DATA_SOCIO)\n",
    "\n",
    "# === 2. Normalizar nomes e chaves ===\n",
    "def normalize_name(n):\n",
    "    return (\n",
    "        str(n)\n",
    "        .strip()\n",
    "        .lower()\n",
    "        .replace(\"ã\", \"a\")\n",
    "        .replace(\"ç\", \"c\")\n",
    "        .replace(\"í\", \"i\")\n",
    "        .replace(\"é\", \"e\")\n",
    "        .replace(\"ú\", \"u\")\n",
    "        .replace(\"ó\", \"o\")\n",
    "    )\n",
    "\n",
    "for df in [df_clima, df_mob, df_socio]:\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    if \"nome_ponto_turistico\" in df.columns:\n",
    "        df[\"key\"] = df[\"nome_ponto_turistico\"].apply(normalize_name)\n",
    "    elif \"nome\" in df.columns:\n",
    "        df[\"key\"] = df[\"nome\"].apply(normalize_name)\n",
    "\n",
    "# === 3. Merge dos datasets ===\n",
    "df_merge = (\n",
    "    df_clima.merge(df_socio, on=\"key\", suffixes=(\"_clima\", \"_socio\"))\n",
    "    .merge(df_mob, on=\"key\", suffixes=(\"\", \"_mob\"))\n",
    ")\n",
    "\n",
    "# === 4. Selecionar colunas finais ===\n",
    "colunas_finais = [\n",
    "    \"nome_ponto_turistico_clima\",\n",
    "    \"provincia_clima\",\n",
    "    \"lat_clima\",\n",
    "    \"lon_clima\",\n",
    "    \"temp_med_anual\",\n",
    "    \"precipitacao_anual\",\n",
    "    \"ndvi\",\n",
    "    \"evi\",\n",
    "    \"ndwi\",\n",
    "    \"altitude\",\n",
    "    \"populacao\",\n",
    "    \"densidade_pop\",\n",
    "    \"pib_per_capita\",\n",
    "    \"idh\",\n",
    "    \"taxa_urbanizacao\",\n",
    "    \"emprego_turismo\",\n",
    "    \"distancia_estrada_principal_km\",\n",
    "    \"distancia_cidade_km\",\n",
    "]\n",
    "\n",
    "# Garantir que as colunas existam\n",
    "colunas_existentes = [c for c in colunas_finais if c in df_merge.columns]\n",
    "\n",
    "# === 5. Criar dataframe final ===\n",
    "df_final = df_merge[colunas_existentes].copy()\n",
    "\n",
    "# === 6. Salvar CSV final ===\n",
    "output_path = Path(\"../data/model_input.csv\")\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\" Model Input salvo em: {output_path}\")\n",
    "print(df_final.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmbienteVirtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
