{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265022d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Coletando POIs para Quedas de Calandula (Malanje)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_quedas_de_calandula.geojson\n",
      "\n",
      " Coletando POIs para Miradouro da Lua (Luanda)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_miradouro_da_lua.geojson\n",
      "\n",
      " Coletando POIs para Museu Kulumbimbi (Zaire)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_museu_kulumbimbi.geojson\n",
      "\n",
      " Coletando POIs para Reserva Parcial do Namibe (Namibe)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_reserva_parcial_do_namibe.geojson\n",
      "\n",
      " Coletando POIs para Fortaleza de S√£o Miguel (Luanda)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_fortaleza_de_s√£o_miguel.geojson\n",
      "\n",
      " Coletando POIs para Ilha do Mussulo (Luanda)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_ilha_do_mussulo.geojson\n",
      "\n",
      " Coletando POIs para C√¢nion do Rio Kalandula (Malanje)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_c√¢nion_do_rio_kalandula.geojson\n",
      "\n",
      " Coletando POIs para Parque Nacional da Qui√ßama (Luanda)...\n",
      " Erro na coleta: No matching features. Check query location, tags, and log.\n",
      " Nenhum POI encontrado em Parque Nacional da Qui√ßama.\n",
      "\n",
      " Coletando POIs para Cristo Rei (Huambo)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_cristo_rei.geojson\n",
      "\n",
      " Coletando POIs para Serra da Leba (Hu√≠la)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_serra_da_leba.geojson\n",
      "\n",
      " Coletando POIs para Fenda da Tundavala (Hu√≠la)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_fenda_da_tundavala.geojson\n",
      "\n",
      " Coletando POIs para Ba√≠a Azul (Benguela)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_ba√≠a_azul.geojson\n",
      "\n",
      " Coletando POIs para Quedas do Rio Chiumbe (Moxico)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_quedas_do_rio_chiumbe.geojson\n",
      "\n",
      " Coletando POIs para Parque Nacional de Cameia (Moxico)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_parque_nacional_de_cameia.geojson\n",
      "\n",
      " Coletando POIs para Grutas do Nzenzo (U√≠ge)...\n",
      "    Salvo: ..\\data\\geoespacial\\pois_grutas_do_nzenzo.geojson\n",
      "\n",
      " Arquivo combinado salvo em: ..\\data\\geoespacial\\pontos_turisticos_angola_raw.geojson\n"
     ]
    }
   ],
   "source": [
    "# carregar dataset rudementar\n",
    "# ==============================================================\n",
    "# CARREGAR DATASET RUDIMENTAR ‚Äî Coleta de POIs do OSM\n",
    "# Angola (Pontos Tur√≠sticos com coordenadas conhecidas)\n",
    "# ==============================================================\n",
    "\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# === Diret√≥rio de sa√≠da ===\n",
    "DATA_DIR = Path(\"../data/geoespacial\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Locais tur√≠sticos (com coordenadas conhecidas) ===\n",
    "locais_turisticos = [\n",
    "    {\"nome\": \"Quedas de Calandula\", \"lat\": -9.075025, \"lon\": 16.001131, \"provincia\": \"Malanje\"},\n",
    "    {\"nome\": \"Miradouro da Lua\", \"lat\": -9.221147, \"lon\": 13.090001, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Museu Kulumbimbi\", \"lat\": -6.264389, \"lon\": 14.245581, \"provincia\": \"Zaire\"},\n",
    "    {\"nome\": \"Reserva Parcial do Namibe\", \"lat\": -15.766760, \"lon\": 12.399914, \"provincia\": \"Namibe\"},\n",
    "    {\"nome\": \"Fortaleza de S√£o Miguel\", \"lat\": -8.808343416048587, \"lon\": 13.223444621289627, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Ilha do Mussulo\", \"lat\": -8.964635, \"lon\":13.050462, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"C√¢nion do Rio Kalandula\", \"lat\": -9.074959, \"lon\": 16.001378, \"provincia\": \"Malanje\"},\n",
    "    {\"nome\": \"Parque Nacional da Qui√ßama\", \"lat\": -9.750007, \"lon\": 13.583333, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Cristo Rei\", \"lat\": -14.940039, \"lon\": 13.511860, \"provincia\": \"Huambo\"},\n",
    "    {\"nome\": \"Serra da Leba\", \"lat\": -15.0788, \"lon\": 13.2397, \"provincia\": \"Hu√≠la\"},\n",
    "    {\"nome\": \"Fenda da Tundavala\", \"lat\": -14.817465, \"lon\": 13.381539, \"provincia\": \"Hu√≠la\"},\n",
    "    {\"nome\": \"Ba√≠a Azul\", \"lat\": -12.627978, \"lon\": 13.234185, \"provincia\": \"Benguela\"},\n",
    "    {\"nome\": \"Quedas do Rio Chiumbe\", \"lat\": -11.021380, \"lon\": 20.203180, \"provincia\": \"Moxico\"},\n",
    "    {\"nome\": \"Parque Nacional de Cameia\", \"lat\": -11.883338, \"lon\": 21.666681, \"provincia\": \"Moxico\"},\n",
    "    {\"nome\": \"Grutas do Nzenzo\", \"lat\": -7.520192, \"lon\":14.565103, \"provincia\": \"U√≠ge\"}\n",
    "]\n",
    "\n",
    "BUFFER_RADIUS = 5000  # 5 km\n",
    "dfs = []\n",
    "\n",
    "# === Tags OSM ‚Äî Turismo + Infraestrutura ===\n",
    "TAGS = {\n",
    "    \"tourism\": True,\n",
    "    \"amenity\": True,\n",
    "    \"leisure\": True,\n",
    "    \"natural\": True,\n",
    "    \"landuse\": True,\n",
    "    \"highway\": True,\n",
    "    \"waterway\": True,\n",
    "    \"power\": True,\n",
    "    \"man_made\": True,\n",
    "    \"railway\": True,\n",
    "    \"building\": True\n",
    "}\n",
    "\n",
    "\n",
    "def coletar_pois(lat, lon, tags, buffer_m):\n",
    "    \"\"\"Retorna os POIs dentro do raio (buffer_m) ao redor das coordenadas.\"\"\"\n",
    "    try:\n",
    "        gdf_ponto = gpd.GeoDataFrame([[\"ponto\", Point(lon, lat)]],\n",
    "                                     columns=[\"nome\", \"geometry\"],\n",
    "                                     crs=\"EPSG:4326\")\n",
    "        area_busca = gdf_ponto.to_crs(3857).buffer(buffer_m).to_crs(4326).iloc[0]\n",
    "\n",
    "        pois = ox.features_from_polygon(area_busca, tags).reset_index()\n",
    "        if pois.empty:\n",
    "            return None\n",
    "\n",
    "        # Garantir colunas\n",
    "        colunas_necessarias = [\n",
    "            \"osm_id\", \"name\", \"tourism\", \"amenity\", \"leisure\",\n",
    "            \"natural\", \"landuse\", \"highway\", \"waterway\",\n",
    "            \"power\", \"man_made\", \"railway\", \"building\", \"geometry\"\n",
    "        ]\n",
    "        for c in colunas_necessarias:\n",
    "            if c not in pois.columns:\n",
    "                pois[c] = None\n",
    "        return pois[colunas_necessarias]\n",
    "    except Exception as e:\n",
    "        print(f\" Erro na coleta: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# === Loop pelos locais ===\n",
    "for item in locais_turisticos:\n",
    "    nome = item[\"nome\"]\n",
    "    lat = item[\"lat\"]\n",
    "    lon = item[\"lon\"]\n",
    "    prov = item[\"provincia\"]\n",
    "\n",
    "    print(f\"\\n Coletando POIs para {nome} ({prov})...\")\n",
    "\n",
    "    pois = coletar_pois(lat, lon, TAGS, BUFFER_RADIUS)\n",
    "\n",
    "    if pois is not None:\n",
    "        # Adicionar metadados\n",
    "        pois[\"ponto_turistico\"] = nome\n",
    "        pois[\"provincia\"] = prov\n",
    "        pois[\"fonte_dados\"] = \"OpenStreetMap\"\n",
    "        pois[\"latitude\"] = pois.to_crs(3857).geometry.centroid.to_crs(4326).y\n",
    "        pois[\"longitude\"] = pois.to_crs(3857).geometry.centroid.to_crs(4326).x\n",
    "\n",
    "        # Salvar individualmente\n",
    "        output_path = DATA_DIR / f\"pois_{nome.replace(' ', '_').lower()}.geojson\"\n",
    "        pois.to_file(output_path, driver=\"GeoJSON\")\n",
    "        print(f\"    Salvo: {output_path}\")\n",
    "\n",
    "        dfs.append(pois)\n",
    "    else:\n",
    "        print(f\" Nenhum POI encontrado em {nome}.\")\n",
    "\n",
    "    time.sleep(1.5)  # respeitar limite de requisi√ß√µes\n",
    "\n",
    "# === Combinar tudo ===\n",
    "if dfs:\n",
    "    pois_final = gpd.GeoDataFrame(pd.concat(dfs, ignore_index=True), crs=\"EPSG:4326\")\n",
    "    output_final = DATA_DIR / \"pontos_turisticos_angola_raw.geojson\"\n",
    "    pois_final.to_file(output_final, driver=\"GeoJSON\")\n",
    "    print(f\"\\n Arquivo combinado salvo em: {output_final}\")\n",
    "else:\n",
    "    print(\"\\n Nenhum POI foi coletado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96df2665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados normalizados salvos em: ..\\data\\geoespacial\\pontos_turisticos_angola_normalizado.geojson\n"
     ]
    }
   ],
   "source": [
    "# Normalizar \n",
    "\n",
    "# ==============================================================\n",
    "# NORMALIZA√á√ÉO DOS DADOS GEOF√çSICOS E DE INFRAESTRUTURA\n",
    "# ==============================================================\n",
    "\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data/geoespacial\")\n",
    "input_path = DATA_DIR / \"pontos_turisticos_angola_raw.geojson\"\n",
    "output_path = DATA_DIR / \"pontos_turisticos_angola_normalizado.geojson\"\n",
    "\n",
    "# ===  Carregar dados brutos ===\n",
    "pois = gpd.read_file(input_path)\n",
    "\n",
    "# ===  Limpeza b√°sica ===\n",
    "if \"osm_id\" in pois.columns:\n",
    "    pois = pois.drop_duplicates(subset=[\"osm_id\"], keep=\"first\")\n",
    "else:\n",
    "    pois = pois.drop_duplicates(subset=[\"name\", \"geometry\"], keep=\"first\")\n",
    "\n",
    "pois = pois[pois.is_valid]\n",
    "pois = pois.dropna(subset=[\"geometry\"])\n",
    "\n",
    "# ===  Garantir colunas cr√≠ticas ===\n",
    "for col in [\"name\", \"tourism\", \"amenity\", \"leisure\", \"natural\", \"landuse\", \n",
    "            \"highway\", \"power\", \"latitude\", \"longitude\"]:\n",
    "    if col not in pois.columns:\n",
    "        pois[col] = None\n",
    "\n",
    "# ===  Corre√ß√£o e normaliza√ß√£o ===\n",
    "pois[\"name\"] = pois[\"name\"].fillna(\"Desconhecido\").astype(str)\n",
    "\n",
    "map_tourism = {\n",
    "    \"guest_house\": \"accommodation\",\n",
    "    \"hotel\": \"accommodation\",\n",
    "    \"motel\": \"accommodation\",\n",
    "    \"museum\": \"culture\",\n",
    "    \"attraction\": \"attraction\"\n",
    "}\n",
    "map_amenity = {\n",
    "    \"restaurant\": \"food_service\",\n",
    "    \"fast_food\": \"food_service\",\n",
    "    \"hospital\": \"health\",\n",
    "    \"school\": \"education\"\n",
    "}\n",
    "\n",
    "pois[\"tourism\"] = pois[\"tourism\"].replace(map_tourism)\n",
    "pois[\"amenity\"] = pois[\"amenity\"].replace(map_amenity)\n",
    "\n",
    "# ===  Vari√°veis derivadas ===\n",
    "pois[\"is_touristic\"] = pois[\"tourism\"].notna().astype(int)\n",
    "pois[\"is_infrastructure\"] = pois[[\"amenity\", \"highway\", \"power\"]].notna().any(axis=1).astype(int)\n",
    "\n",
    "# ===  Salvar resultado ===\n",
    "pois.to_file(output_path, driver=\"GeoJSON\")\n",
    "print(f\" Dados normalizados salvos em: {output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36bcbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dados de mobilidade normalizados salvos em: ..\\data\\climatic-environmental\\mobilidade_infra_normalizado.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# NORMALIZA√á√ÉO DOS DADOS DE MOBILIDADE E DE INFRAESTRUTURA\n",
    "# ==============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Diret√≥rio e arquivo ===\n",
    "DATA_DIR = Path(\"../data/climatic-environmental\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "input_path = DATA_DIR / \"mobilidade_infra.csv\"\n",
    "\n",
    "# === Carregar ===\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# === Normalizar nomes de colunas ===\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(r'\\s+', '_', regex=True)\n",
    "\n",
    "# === Preenchimento b√°sico ===\n",
    "num_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "for c in num_cols:\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].fillna(\"desconhecido\")\n",
    "\n",
    "# === Limites plaus√≠veis ===\n",
    "if \"velocidade_media_kmh\" in df.columns:\n",
    "    df[\"velocidade_media_kmh\"] = df[\"velocidade_media_kmh\"].clip(lower=0, upper=200)\n",
    "\n",
    "if \"capacidade\" in df.columns:\n",
    "    df[\"capacidade\"] = df[\"capacidade\"].clip(lower=0)\n",
    "\n",
    "if \"fluxo_diario\" in df.columns:\n",
    "    df[\"fluxo_diario\"] = df[\"fluxo_diario\"].clip(lower=0)\n",
    "\n",
    "# === Datas ===\n",
    "for date_col in [\"date\", \"data\", \"timestamp\"]:\n",
    "    if date_col in df.columns:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "\n",
    "# === Normalizar categorias de infraestrutura ===\n",
    "infra_col_candidates = [c for c in df.columns if c in (\"tipo\", \"tipo_infra\", \"infra_type\", \"category\")]\n",
    "if infra_col_candidates:\n",
    "    infra_col = infra_col_candidates[0]\n",
    "    df[infra_col] = df[infra_col].astype(str).str.lower()\n",
    "    df[\"is_road\"] = df[infra_col].str.contains(r\"road|highway|estrada\", na=False).astype(int)\n",
    "    df[\"is_rail\"] = df[infra_col].str.contains(r\"rail|ferrovia\", na=False).astype(int)\n",
    "    df[\"is_port\"] = df[infra_col].str.contains(r\"port|porto\", na=False).astype(int)\n",
    "    df[\"is_airport\"] = df[infra_col].str.contains(r\"airport|aeroporto\", na=False).astype(int)\n",
    "\n",
    "# === Coordenadas -> GeoDataFrame ===\n",
    "lat_candidates = [c for c in df.columns if c in (\"latitude\", \"lat\", \"y\")]\n",
    "lon_candidates = [c for c in df.columns if c in (\"longitude\", \"lon\", \"lng\", \"x\")]\n",
    "\n",
    "output_csv = DATA_DIR / \"mobilidade_infra_normalizado.csv\"\n",
    "output_geo = DATA_DIR / \"mobilidade_infra_normalizado.geojson\"\n",
    "\n",
    "if lat_candidates and lon_candidates:\n",
    "    lat_col = lat_candidates[0]\n",
    "    lon_col = lon_candidates[0]\n",
    "    df = df.dropna(subset=[lat_col, lon_col])\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df.copy(),\n",
    "        geometry=gpd.points_from_xy(df[lon_col].astype(float), df[lat_col].astype(float)),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    gdf.to_file(output_geo, driver=\"GeoJSON\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Dados de mobilidade normalizados salvos em:\\n   - {output_csv}\\n   - {output_geo}\")\n",
    "else:\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Dados de mobilidade normalizados salvos em: {output_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c491642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados clim√°ticos-ambientais normalizados salvos em: ..\\data\\climatic-environmental\\clima_lulc_normalizado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ==============================================================\n",
    "# NORMALIZA√á√ÉO DOS DADOS CLIMATICOS-AMBIENTAIS\n",
    "\n",
    "# ==============================================================\n",
    "# === Diret√≥rio e arquivos ===\n",
    "DATA_DIR = Path(\"../data/climatic-environmental\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "input_clima = DATA_DIR / \"exemplo.csv\"\n",
    "df_clima = pd.read_csv(input_clima)\n",
    "\n",
    "# === Normaliza√ß√£o dos dados ===\n",
    "# Temperatura m√©dia anual (¬∞C)\n",
    "df_clima['temp_med_anual'] = df_clima['temp_med_anual'].clip(20, 35)\n",
    "\n",
    "# Precipita√ß√£o anual (mm)\n",
    "df_clima['precipitacao_anual'] = df_clima['precipitacao_anual'].clip(0, 2000)\n",
    "\n",
    "# √çndices de vegeta√ß√£o e √°gua\n",
    "for col in ['NDVI', 'EVI', 'NDWI']:\n",
    "    df_clima[col] = df_clima[col].clip(-1, 1)\n",
    "\n",
    "# C√≥digos LULC (Land Use Land Cover)\n",
    "df_clima['LULC_codigo'] = df_clima['LULC_codigo'].astype('category')\n",
    "\n",
    "# Altitude (m)\n",
    "df_clima['altitude'] = df_clima['altitude'].clip(0, 2500)\n",
    "\n",
    "# === Salvar dados normalizados ===\n",
    "output_path = DATA_DIR / \"clima_lulc_normalizado.csv\"\n",
    "df_clima.to_csv(output_path, index=False)\n",
    "print(f\" Dados clim√°ticos-ambientais normalizados salvos em: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f57fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados econ√¥micos-sociais normalizados salvos em: ..\\data\\economicsocial\\economicsocial_normalizado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ==============================================================\n",
    "# NORMALIZA√á√ÉO DOS DADOS ECON√îMICOS-SOCIAIS\n",
    "# ==============================================================\n",
    "# === Diret√≥rio e arquivos ===\n",
    "DATA_DIR = Path(\"../data/economicsocial\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "input_eco = DATA_DIR / \"dados_socioeconomicos.csv\"\n",
    "df_eco = pd.read_csv(input_eco)\n",
    "\n",
    "# === Normaliza√ß√£o dos dados ===\n",
    "# PIB per capita (USD)\n",
    "df_eco['pib_per_capita'] = df_eco['pib_per_capita'].clip(500, 5000)\n",
    "\n",
    "# Popula√ß√£o\n",
    "df_eco['populacao'] = df_eco['populacao'].clip(1000, 1000000)\n",
    "\n",
    "# √çndice de desenvolvimento humano\n",
    "df_eco['idh'] = df_eco['idh'].clip(0, 1)\n",
    "\n",
    "# Densidade populacional (hab/km¬≤)\n",
    "df_eco['densidade_pop'] = df_eco['densidade_pop'].clip(0, 1000)\n",
    "\n",
    "# Taxa de urbaniza√ß√£o (%)\n",
    "df_eco['taxa_urbanizacao'] = df_eco['taxa_urbanizacao'].clip(0, 100)\n",
    "\n",
    "# === Salvar dados normalizados ===\n",
    "output_path = DATA_DIR / \"economicsocial_normalizado.csv\"\n",
    "df_eco.to_csv(output_path, index=False)\n",
    "print(f\" Dados econ√¥micos-sociais normalizados salvos em: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b056fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vari√°veis espaciais geradas e salvas em: ..\\data\\geoespacial\\pontos_turisticos_angola_raw.geojson\n"
     ]
    }
   ],
   "source": [
    "# Gerar vari√°veis espaciais \n",
    "# ============================================================== \n",
    "# GERAR VARI√ÅVEIS ESPACIAIS\n",
    "# ==============================================================\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = Path(\"../data/geoespacial\")\n",
    "input_path = DATA_DIR / \"pontos_turisticos_angola_normalizado.geojson\"\n",
    "output_path = DATA_DIR / \"pontos_turisticos_angola_raw.geojson\"\n",
    "\n",
    "# === Carregar dados normalizados ===\n",
    "pois = gpd.read_file(input_path)\n",
    "\n",
    "# === Converter para proje√ß√£o m√©trica (metros) para c√°lculos espaciais ===\n",
    "pois = pois.to_crs(epsg=3857)\n",
    "\n",
    "# === Exemplo 1: Calcular centroid de cada ponto tur√≠stico (se houver pol√≠gonos) ===\n",
    "# (No caso de pontos simples, √© s√≥ o pr√≥prio ponto)\n",
    "pois['centroid_x'] = pois.geometry.centroid.x\n",
    "pois['centroid_y'] = pois.geometry.centroid.y\n",
    "\n",
    "# === Exemplo 2: Dist√¢ncia at√© o ponto tur√≠stico mais pr√≥ximo ===\n",
    "# Criar uma fun√ß√£o para calcular a menor dist√¢ncia entre cada ponto\n",
    "def nearest_distance(point, others):\n",
    "    # Retorna a menor dist√¢ncia (em metros) at√© outro ponto\n",
    "    distances = others.geometry.distance(point)\n",
    "    distances = distances[distances > 0]  # ignora dist√¢ncia zero (o pr√≥prio ponto)\n",
    "    if len(distances) > 0:\n",
    "        return distances.min()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "pois['dist_to_nearest_poi'] = pois.geometry.apply(lambda p: nearest_distance(p, pois))\n",
    "\n",
    "# === Exemplo 3: Buffer / contagem de POIs pr√≥ximos (densidade) ===\n",
    "BUFFER_RADIUS = 1000  # metros\n",
    "pois['pois_within_1km'] = pois.geometry.apply(lambda g: pois[pois.geometry.within(g.buffer(BUFFER_RADIUS))].shape[0] - 1) \n",
    "# -1 para excluir o pr√≥prio ponto\n",
    "\n",
    "# === Exemplo 4: Flag de proximidade a categorias espec√≠ficas ===\n",
    "# Por exemplo, se existe hospital ou escola em 1km\n",
    "def has_category_nearby(point, category_col, category_value, radius=1000):\n",
    "    buffer = point.buffer(radius)\n",
    "    subset = pois[(pois[category_col] == category_value) & (pois.geometry.within(buffer))]\n",
    "    return int(len(subset) > 0)\n",
    "\n",
    "pois['hospital_nearby'] = pois.geometry.apply(lambda g: has_category_nearby(g, 'amenity', 'hospital'))\n",
    "pois['school_nearby'] = pois.geometry.apply(lambda g: has_category_nearby(g, 'amenity', 'school'))\n",
    "\n",
    "# === Salvar dataset com vari√°veis espaciais ===\n",
    "pois = pois.to_crs(epsg=4326)  # voltar para lat/lon\n",
    "pois.to_file(output_path, driver=\"GeoJSON\")\n",
    "print(f\" Vari√°veis espaciais geradas e salvas em: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6845c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Carregando camadas de dados...\n",
      "üîπ Normalizando nomes e criando chaves...\n",
      "üîπ Realizando jun√ß√£o sem√¢ntica (clima + socioecon√¥mico + mobilidade)...\n",
      "üîπ Realizando jun√ß√£o espacial com dados geogr√°ficos...\n",
      " Salvando arquivos em: ..\\data\\integrado\n",
      " Integra√ß√£o conclu√≠da com sucesso!\n",
      " Arquivos gerados:\n",
      " - dataset_integrado.csv\n",
      " - dataset_integrado.geojson\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# ============================================================\n",
    "# üîπ FUN√á√ïES AUXILIARES\n",
    "# ============================================================\n",
    "\n",
    "def normalizar(texto):\n",
    "    \"\"\"Remove acentos, espa√ßos extras e converte em min√∫sculas.\"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    texto = str(texto).strip().lower()\n",
    "    texto = re.sub(r\"[√°√†√£√¢√§]\", \"a\", texto)\n",
    "    texto = re.sub(r\"[√©√®√™√´]\", \"e\", texto)\n",
    "    texto = re.sub(r\"[√≠√¨√Æ√Ø]\", \"i\", texto)\n",
    "    texto = re.sub(r\"[√≥√≤√µ√¥√∂]\", \"o\", texto)\n",
    "    texto = re.sub(r\"[√∫√π√ª√º]\", \"u\", texto)\n",
    "    texto = re.sub(r\"√ß\", \"c\", texto)\n",
    "    texto = re.sub(r\"[^a-z0-9 ]\", \"\", texto)\n",
    "    return texto\n",
    "\n",
    "\n",
    "def carregar_csv(caminho):\n",
    "    \"\"\"L√™ CSV corrigindo encoding e normalizando nomes de colunas.\"\"\"\n",
    "    df = pd.read_csv(caminho, encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "    df.columns = [normalizar(c) for c in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def adicionar_chave(df, colunas_possiveis):\n",
    "    \"\"\"Adiciona coluna 'key' com nome normalizado.\"\"\"\n",
    "    for col in df.columns:\n",
    "        if any(col.startswith(c) for c in colunas_possiveis):\n",
    "            df[\"key\"] = df[col].astype(str).apply(normalizar)\n",
    "            return df\n",
    "    raise ValueError(f\"‚ùå Nenhuma coluna de nome encontrada. Colunas dispon√≠veis: {list(df.columns)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üîπ CAMINHOS DOS DADOS\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = Path(\"../data\")\n",
    "PATH_GEO_NORM = BASE_DIR / \"geoespacial/pontos_turisticos_angola_normalizado.geojson\"\n",
    "PATH_GEO_RAW = BASE_DIR / \"geoespacial/pontos_turisticos_angola_raw.geojson\"\n",
    "PATH_CLIMA = BASE_DIR / \"climatic-environmental/clima_lulc_normalizado.csv\"\n",
    "PATH_MOB = BASE_DIR / \"climatic-environmental/mobilidade_infra_normalizado.csv\"\n",
    "PATH_SOCIO = BASE_DIR / \"economicsocial/economicsocial_normalizado.csv\"\n",
    "\n",
    "# ============================================================\n",
    "# üîπ CARREGAR CAMADAS\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîπ Carregando camadas de dados...\")\n",
    "\n",
    "gdf_norm = gpd.read_file(PATH_GEO_NORM)\n",
    "gdf_raw = gpd.read_file(PATH_GEO_RAW)\n",
    "df_clima = carregar_csv(PATH_CLIMA)\n",
    "df_mob = carregar_csv(PATH_MOB)\n",
    "df_socio = carregar_csv(PATH_SOCIO)\n",
    "\n",
    "# ============================================================\n",
    "# üîπ ADICIONAR CHAVES NORMALIZADAS\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîπ Normalizando nomes e criando chaves...\")\n",
    "\n",
    "gdf_norm = adicionar_chave(gdf_norm, [\"ponto_turistico\", \"name\", \"nome\"])\n",
    "gdf_raw = adicionar_chave(gdf_raw, [\"ponto_turistico\", \"name\", \"nome\"])\n",
    "df_clima = adicionar_chave(df_clima, [\"nome_ponto_turistico\", \"nome\"])\n",
    "df_mob = adicionar_chave(df_mob, [\"nome\"])\n",
    "df_socio = adicionar_chave(df_socio, [\"nome\"])\n",
    "\n",
    "# ============================================================\n",
    "# üîπ JUN√á√ÉO SEM√ÇNTICA ‚Äî CLIMA + SOCIO + MOBILIDADE\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîπ Realizando jun√ß√£o sem√¢ntica (clima + socioecon√¥mico + mobilidade)...\")\n",
    "\n",
    "df_semantico = df_clima.merge(df_socio, on=\"key\", how=\"outer\", suffixes=(\"_clima\", \"_socio\"))\n",
    "df_semantico = df_semantico.merge(df_mob, on=\"key\", how=\"outer\", suffixes=(\"\", \"_mob\"))\n",
    "\n",
    "# ============================================================\n",
    "# üîπ JUN√á√ÉO ESPACIAL ‚Äî COM GEOESPACIAL NORMALIZADO E RAW\n",
    "# ============================================================\n",
    "\n",
    "print(\"üîπ Realizando jun√ß√£o espacial com dados geogr√°ficos...\")\n",
    "\n",
    "# Converter para GeoDataFrame com base em coordenadas (lat/lon)\n",
    "if \"longitude\" in gdf_norm.columns and \"latitude\" in gdf_norm.columns:\n",
    "    gdf_norm[\"geometry\"] = gdf_norm.apply(lambda x: Point(x[\"longitude\"], x[\"latitude\"]), axis=1)\n",
    "gdf_norm = gpd.GeoDataFrame(gdf_norm, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Merge final com base na chave\n",
    "gdf_final = gdf_norm.merge(df_semantico, on=\"key\", how=\"left\")\n",
    "gdf_final = gdf_final.merge(gdf_raw.drop(columns=[\"geometry\"]), on=\"key\", how=\"left\", suffixes=(\"\", \"_raw\"))\n",
    "\n",
    "# ============================================================\n",
    "# üîπ EXPORTAR RESULTADOS\n",
    "# ============================================================\n",
    "\n",
    "OUTPUT_DIR = BASE_DIR / \"integrado\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_out = OUTPUT_DIR / \"dataset_integrado.csv\"\n",
    "geojson_out = OUTPUT_DIR / \"dataset_integrado.geojson\"\n",
    "\n",
    "print(f\" Salvando arquivos em: {OUTPUT_DIR}\")\n",
    "gdf_final.to_csv(csv_out, index=False, encoding=\"utf-8\")\n",
    "gdf_final.to_file(geojson_out, driver=\"GeoJSON\")\n",
    "\n",
    "print(\" Integra√ß√£o conclu√≠da com sucesso!\")\n",
    "print(f\" Arquivos gerados:\\n - {csv_out.name}\\n - {geojson_out.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae13a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model Input salvo em: ..\\data\\model_input.csv\n",
      "  nome_ponto_turistico_clima provincia_clima  lat_clima  lon_clima  \\\n",
      "0        Quedas de Calandula         Malanje  -9.075025  16.001131   \n",
      "1           Miradouro da Lua          Luanda  -9.221147  13.090001   \n",
      "2           Museu Kulumbimbi           Zaire  -6.264389  14.245581   \n",
      "3  Reserva Parcial do Namibe          Namibe -15.766760  12.399914   \n",
      "4    Fortaleza de S√£o Miguel          Luanda  -8.808343  13.223445   \n",
      "\n",
      "   temp_med_anual  precipitacao_anual  ndvi   evi  ndwi  altitude  populacao  \\\n",
      "0            28.8               218.9  0.80  0.16  0.02     287.0      95533   \n",
      "1            24.8               304.1  0.77  0.68  0.08    1148.0      52641   \n",
      "2            27.8               343.0  0.20  0.46  0.08     683.0      54008   \n",
      "3            24.3               286.7  0.15  0.60  0.04     362.0     166079   \n",
      "4            28.1               158.6  0.62  0.47  0.16    1192.0     192436   \n",
      "\n",
      "   densidade_pop  pib_per_capita    idh  taxa_urbanizacao  emprego_turismo  \\\n",
      "0          412.4         4015.12  0.543              50.1             14.0   \n",
      "1          422.9         2765.22  0.590              69.3             13.1   \n",
      "2          151.1         1998.99  0.726              41.5             12.5   \n",
      "3          200.8         1815.76  0.624              44.9              7.5   \n",
      "4          250.0         3426.64  0.678              70.6              8.8   \n",
      "\n",
      "   distancia_estrada_principal_km  distancia_cidade_km  \n",
      "0                             2.7                157.6  \n",
      "1                             1.4                 11.0  \n",
      "2                             6.0                 38.5  \n",
      "3                             6.6                106.4  \n",
      "4                             4.3                129.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# =====================================================\n",
    "#  Gerar model_input.csv consolidado e pronto p/ ML\n",
    "# =====================================================\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "DATA_CLIMA = Path(\"../data/climatic-environmental/clima_lulc_normalizado.csv\")\n",
    "DATA_MOB = Path(\"../data/climatic-environmental/mobilidade_infra_normalizado.csv\")\n",
    "DATA_SOCIO = Path(\"../data/economicsocial/economicsocial_normalizado.csv\")\n",
    "\n",
    "# === 1. Carregar dados ===\n",
    "df_clima = pd.read_csv(DATA_CLIMA)\n",
    "df_mob = pd.read_csv(DATA_MOB)\n",
    "df_socio = pd.read_csv(DATA_SOCIO)\n",
    "\n",
    "# === 2. Normalizar nomes e chaves ===\n",
    "def normalize_name(n):\n",
    "    return (\n",
    "        str(n)\n",
    "        .strip()\n",
    "        .lower()\n",
    "        .replace(\"√£\", \"a\")\n",
    "        .replace(\"√ß\", \"c\")\n",
    "        .replace(\"√≠\", \"i\")\n",
    "        .replace(\"√©\", \"e\")\n",
    "        .replace(\"√∫\", \"u\")\n",
    "        .replace(\"√≥\", \"o\")\n",
    "    )\n",
    "\n",
    "for df in [df_clima, df_mob, df_socio]:\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    if \"nome_ponto_turistico\" in df.columns:\n",
    "        df[\"key\"] = df[\"nome_ponto_turistico\"].apply(normalize_name)\n",
    "    elif \"nome\" in df.columns:\n",
    "        df[\"key\"] = df[\"nome\"].apply(normalize_name)\n",
    "\n",
    "# === 3. Merge dos datasets ===\n",
    "df_merge = (\n",
    "    df_clima.merge(df_socio, on=\"key\", suffixes=(\"_clima\", \"_socio\"))\n",
    "    .merge(df_mob, on=\"key\", suffixes=(\"\", \"_mob\"))\n",
    ")\n",
    "\n",
    "# === 4. Selecionar colunas finais ===\n",
    "colunas_finais = [\n",
    "    \"nome_ponto_turistico_clima\",\n",
    "    \"provincia_clima\",\n",
    "    \"lat_clima\",\n",
    "    \"lon_clima\",\n",
    "    \"temp_med_anual\",\n",
    "    \"precipitacao_anual\",\n",
    "    \"ndvi\",\n",
    "    \"evi\",\n",
    "    \"ndwi\",\n",
    "    \"altitude\",\n",
    "    \"populacao\",\n",
    "    \"densidade_pop\",\n",
    "    \"pib_per_capita\",\n",
    "    \"idh\",\n",
    "    \"taxa_urbanizacao\",\n",
    "    \"emprego_turismo\",\n",
    "    \"distancia_estrada_principal_km\",\n",
    "    \"distancia_cidade_km\",\n",
    "]\n",
    "\n",
    "# Garantir que as colunas existam\n",
    "colunas_existentes = [c for c in colunas_finais if c in df_merge.columns]\n",
    "\n",
    "# === 5. Criar dataframe final ===\n",
    "df_final = df_merge[colunas_existentes].copy()\n",
    "\n",
    "# === 6. Salvar CSV final ===\n",
    "output_path = Path(\"../data/model_input.csv\")\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\" Model Input salvo em: {output_path}\")\n",
    "print(df_final.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmbienteVirtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
