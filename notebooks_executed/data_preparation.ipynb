{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265022d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T06:26:49.390082Z",
     "iopub.status.busy": "2025-11-07T06:26:49.388905Z",
     "iopub.status.idle": "2025-11-07T06:27:40.449436Z",
     "shell.execute_reply": "2025-11-07T06:27:40.446815Z"
    },
    "papermill": {
     "duration": 51.078297,
     "end_time": "2025-11-07T06:27:40.451272",
     "exception": false,
     "start_time": "2025-11-07T06:26:49.372975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iniciando a coleta de dados do OpenStreetMap...\n",
      "\n",
      " Processando: Quedas de Calandula (Malanje)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 79 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Miradouro da Lua (Luanda)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 159 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Museu Kulumbimbi (Zaire)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 1153 features encontradas.\n",
      "    ‚Ü≥ Reduzido para uma amostra aleat√≥ria de 250 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Reserva Parcial do Namibe (Namibe)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 2 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Fortaleza de S√£o Miguel (Luanda)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 11967 features encontradas.\n",
      "    ‚Ü≥ Reduzido para uma amostra aleat√≥ria de 250 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Ilha do Mussulo (Luanda)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 106 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Serra da Leba (Huila)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 42 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Cristo Rei Lubango (Hu√≠la)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 17026 features encontradas.\n",
      "    ‚Ü≥ Reduzido para uma amostra aleat√≥ria de 250 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Serra da Leba (Hu√≠la)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 51 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Fenda da Tundavala (Hu√≠la)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 82 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Ba√≠a Azul (Benguela)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 853 features encontradas.\n",
      "    ‚Ü≥ Reduzido para uma amostra aleat√≥ria de 250 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Quedas do Rio Chiumbe (Moxico)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 180 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Parque Nacional de Cameia (Moxico)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚Ü≥ 1 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processando: Grutas do Nzenzo (U√≠ge)...\n",
      "    ‚Ü≥ 17 features encontradas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Combinando todos os dados coletados...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processo conclu√≠do com sucesso!\n",
      "   Arquivo bruto salvo em: ..\\data\\geoespacial\\pontos_turisticos_angola_raw.geojson\n",
      "   Total de features coletadas: 1719\n",
      "\n",
      "--- Verifica√ß√£o da Estrutura do DataFrame Final ---\n",
      "Colunas presentes no arquivo final (amostra):\n",
      "       ponto_turistico provincia   poi_lat    poi_lon          feature_name  \\\n",
      "0  Quedas de Calandula   Malanje -9.075025  16.001131   Quedas de Calandula   \n",
      "1  Quedas de Calandula   Malanje -9.075025  16.001131                   NaN   \n",
      "2  Quedas de Calandula   Malanje -9.075025  16.001131                   NaN   \n",
      "3  Quedas de Calandula   Malanje -9.075025  16.001131                   NaN   \n",
      "4  Quedas de Calandula   Malanje -9.075025  16.001131  Estrada de Calandula   \n",
      "\n",
      "   feature_lat  feature_lon    tourism amenity  \n",
      "0    -9.074067    16.000316        NaN     NaN  \n",
      "1    -9.074009    15.998896        NaN     NaN  \n",
      "2    -9.074206    16.002487        NaN     NaN  \n",
      "3    -9.077999    16.002056  camp_site     NaN  \n",
      "4    -9.111147    15.970919        NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# C√âLULA 1: COLETA DE DADOS GEOESPACIAIS (POIs) DO OSM - VERS√ÉO CORRIGIDA\n",
    "# ====================================================================\n",
    "\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# --- 1. CONFIGURA√á√ïES ---\n",
    "print(\" Iniciando a coleta de dados do OpenStreetMap...\")\n",
    "\n",
    "DATA_DIR = Path(\"../data/geoespacial\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LIMITE_FEATURES_POR_POI = 250  # Aumentado para capturar mais dados para agrega√ß√£o\n",
    "BUFFER_RADIUS_M = 5000\n",
    "PAUSA_ENTRE_REQUISICOES_S = 1.5\n",
    "\n",
    "locais_turisticos = [\n",
    "    {\"nome\": \"Quedas de Calandula\", \"lat\": -9.075025, \"lon\": 16.001131, \"provincia\": \"Malanje\"},\n",
    "    {\"nome\": \"Miradouro da Lua\", \"lat\": -9.221147, \"lon\": 13.090001, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Museu Kulumbimbi\", \"lat\": -6.264389, \"lon\": 14.245581, \"provincia\": \"Zaire\"},\n",
    "    {\"nome\": \"Reserva Parcial do Namibe\", \"lat\": -15.766760, \"lon\": 12.399914, \"provincia\": \"Namibe\"},\n",
    "    {\"nome\": \"Fortaleza de S√£o Miguel\", \"lat\": -8.808343, \"lon\": 13.223444, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Ilha do Mussulo\", \"lat\": -8.964635, \"lon\": 13.050462, \"provincia\": \"Luanda\"},\n",
    "    {\"nome\": \"Serra da Leba\", \"lat\": -15.071753, \"lon\": 13.236296, \"provincia\": \"Huila\"},\n",
    "    {\"nome\": \"Cristo Rei Lubango\", \"lat\": -14.940039, \"lon\": 13.511860, \"provincia\": \"Hu√≠la\"},\n",
    "    {\"nome\": \"Serra da Leba\", \"lat\": -15.0788, \"lon\": 13.2397, \"provincia\": \"Hu√≠la\"},\n",
    "    {\"nome\": \"Fenda da Tundavala\", \"lat\": -14.817465, \"lon\": 13.381539, \"provincia\": \"Hu√≠la\"},\n",
    "    {\"nome\": \"Ba√≠a Azul\", \"lat\": -12.627978, \"lon\": 13.234185, \"provincia\": \"Benguela\"},\n",
    "    {\"nome\": \"Quedas do Rio Chiumbe\", \"lat\": -11.021380, \"lon\": 20.203180, \"provincia\": \"Moxico\"},\n",
    "    {\"nome\": \"Parque Nacional de Cameia\", \"lat\": -11.883338, \"lon\": 21.666681, \"provincia\": \"Moxico\"},\n",
    "    {\"nome\": \"Grutas do Nzenzo\", \"lat\": -7.520192, \"lon\": 14.565103, \"provincia\": \"U√≠ge\"}\n",
    "]\n",
    "\n",
    "TAGS_OSM = {\n",
    "    \"tourism\": True, \"amenity\": True, \"leisure\": True, \"natural\": True,\n",
    "    \"landuse\": True, \"highway\": True, \"waterway\": True, \"power\": True,\n",
    "    \"man_made\": True, \"railway\": True, \"building\": True\n",
    "}\n",
    "\n",
    "# --- 2. FUN√á√ÉO DE COLETA (sem altera√ß√µes) ---\n",
    "\n",
    "def coletar_features_osm(lat, lon, tags, buffer_m):\n",
    "    \"\"\"Retorna um GeoDataFrame com as features do OSM dentro de um buffer.\"\"\"\n",
    "    try:\n",
    "        ponto_central = gpd.GeoDataFrame([[\"ponto\", Point(lon, lat)]], columns=[\"nome\", \"geometry\"], crs=\"EPSG:4326\")\n",
    "        area_busca = ponto_central.to_crs(3857).buffer(buffer_m).to_crs(4326).iloc[0]\n",
    "        gdf_features = ox.features_from_polygon(area_busca, tags).reset_index()\n",
    "        return gdf_features\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚Ü≥   Aviso durante a coleta: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 3. LOOP DE EXECU√á√ÉO ---\n",
    "\n",
    "lista_gdfs_coletados = []\n",
    "\n",
    "for local in locais_turisticos:\n",
    "    print(f\"\\n Processando: {local['nome']} ({local['provincia']})...\")\n",
    "\n",
    "    features = coletar_features_osm(local['lat'], local['lon'], TAGS_OSM, BUFFER_RADIUS_M)\n",
    "\n",
    "    if features is not None and not features.empty:\n",
    "        total_encontrado = len(features)\n",
    "        print(f\"    ‚Ü≥ {total_encontrado} features encontradas.\")\n",
    "\n",
    "        if total_encontrado > LIMITE_FEATURES_POR_POI:\n",
    "            features = features.sample(n=LIMITE_FEATURES_POR_POI, random_state=42)\n",
    "            print(f\"    ‚Ü≥ Reduzido para uma amostra aleat√≥ria de {len(features)} features.\")\n",
    "        \n",
    "        # --- ENRIQUECIMENTO E PADRONIZA√á√ÉO ---\n",
    "        features['ponto_turistico'] = local['nome']\n",
    "        features['provincia'] = local['provincia']\n",
    "        \n",
    "        # ### ALTERA√á√ÉO PRINCIPAL ###\n",
    "        # Adiciona as coordenadas do PONTO TUR√çSTICO CENTRAL a cada linha.\n",
    "        # Isso √© essencial para a agrega√ß√£o posterior.\n",
    "        features['poi_lat'] = local['lat']\n",
    "        features['poi_lon'] = local['lon']\n",
    "        \n",
    "        # Calcula a lat/lon de cada feature individual (centroide)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            centroids = features.to_crs(3857).geometry.centroid.to_crs(4326)\n",
    "            features['feature_lat'] = centroids.y\n",
    "            features['feature_lon'] = centroids.x\n",
    "        \n",
    "        lista_gdfs_coletados.append(features)\n",
    "    else:\n",
    "        print(f\"    ‚Ü≥ Nenhuma feature encontrada.\")\n",
    "        \n",
    "    time.sleep(PAUSA_ENTRE_REQUISICOES_S)\n",
    "\n",
    "# --- 4. COMBINA√á√ÉO FINAL E SALVAMENTO ---\n",
    "\n",
    "if lista_gdfs_coletados:\n",
    "    print(\"\\nüîπ Combinando todos os dados coletados...\")\n",
    "    gdf_final_raw = gpd.GeoDataFrame(pd.concat(lista_gdfs_coletados, ignore_index=True), crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Renomear 'name' para 'feature_name' para clareza\n",
    "    if 'name' in gdf_final_raw.columns:\n",
    "        gdf_final_raw = gdf_final_raw.rename(columns={'name': 'feature_name'})\n",
    "    \n",
    "    output_path = DATA_DIR / \"pontos_turisticos_angola_raw.geojson\"\n",
    "    gdf_final_raw.to_file(output_path, driver=\"GeoJSON\")\n",
    "    \n",
    "    print(f\"\\n Processo conclu√≠do com sucesso!\")\n",
    "    print(f\"   Arquivo bruto salvo em: {output_path}\")\n",
    "    print(f\"   Total de features coletadas: {len(gdf_final_raw)}\")\n",
    "\n",
    "    print(\"\\n--- Verifica√ß√£o da Estrutura do DataFrame Final ---\")\n",
    "    print(\"Colunas presentes no arquivo final (amostra):\")\n",
    "    # ### ALTERA√á√ÉO NA VERIFICA√á√ÉO ###\n",
    "    # Mostra as colunas novas e mais importantes\n",
    "    cols_to_check = [\n",
    "        'ponto_turistico', 'provincia', 'poi_lat', 'poi_lon', \n",
    "        'feature_name', 'feature_lat', 'feature_lon', 'tourism', 'amenity'\n",
    "    ]\n",
    "    existing_cols_to_check = [c for c in cols_to_check if c in gdf_final_raw.columns]\n",
    "    print(gdf_final_raw[existing_cols_to_check].head())\n",
    "else:\n",
    "    print(\"\\n Nenhuma feature foi coletada em nenhuma das localidades.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96df2665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T06:27:40.468083Z",
     "iopub.status.busy": "2025-11-07T06:27:40.467175Z",
     "iopub.status.idle": "2025-11-07T06:27:50.631999Z",
     "shell.execute_reply": "2025-11-07T06:27:50.630393Z"
    },
    "papermill": {
     "duration": 10.174808,
     "end_time": "2025-11-07T06:27:50.633263",
     "exception": false,
     "start_time": "2025-11-07T06:27:40.458455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iniciando o processamento completo dos dados geoespaciais...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Arquivo bruto 'pontos_turisticos_angola_raw.geojson' carregado com 1719 features.\n",
      " Realizando limpeza...\n",
      "  1676 features restantes ap√≥s limpeza.\n",
      "Normalizando categorias de 'tourism' e 'amenity'...\n",
      " Categorias normalizadas.\n",
      " Iniciando engenharia de features espaciais (c√°lculos em metros)...\n",
      "   - Calculando dist√¢ncia √† feature mais pr√≥xima...\n",
      "   - Contando features em um raio de 1km...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Vari√°veis espaciais calculadas.\n",
      " Finalizando e salvando o GeoDataFrame enriquecido...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Processo conclu√≠do! Arquivo normalizado e enriquecido salvo em: ..\\data\\geoespacial\\pontos_turisticos_angola_normalizado.geojson\n",
      "   O arquivo final tem 1676 linhas e 528 colunas.\n",
      "\n",
      "--- Amostra do Dataset Enriquecido ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ponto_turistico</th>\n",
       "      <th>provincia</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>tourism</th>\n",
       "      <th>amenity</th>\n",
       "      <th>dist_nearest_feature_m</th>\n",
       "      <th>features_within_1km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>83.325233</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>48.478089</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>113.281622</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>None</td>\n",
       "      <td>camp_site</td>\n",
       "      <td>None</td>\n",
       "      <td>27.721497</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>Estrada de Calandula</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2375.771517</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ponto_turistico provincia          feature_name    tourism amenity  \\\n",
       "0  Quedas de Calandula   Malanje   Quedas de Calandula       None    None   \n",
       "1  Quedas de Calandula   Malanje                  None       None    None   \n",
       "2  Quedas de Calandula   Malanje                  None       None    None   \n",
       "3  Quedas de Calandula   Malanje                  None  camp_site    None   \n",
       "4  Quedas de Calandula   Malanje  Estrada de Calandula       None    None   \n",
       "\n",
       "   dist_nearest_feature_m  features_within_1km  \n",
       "0               83.325233                   28  \n",
       "1               48.478089                   28  \n",
       "2              113.281622                   29  \n",
       "3               27.721497                   29  \n",
       "4             2375.771517                    5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# C√âLULA 2: NORMALIZA√á√ÉO, ENRIQUECIMENTO E ENGENHARIA ESPACIAL (COMBINADA)\n",
    "# ====================================================================\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. CONFIGURA√á√ÉO E CARREGAMENTO ---\n",
    "print(\" Iniciando o processamento completo dos dados geoespaciais...\")\n",
    "DATA_DIR = Path(\"../data/geoespacial\")\n",
    "input_path = DATA_DIR / \"pontos_turisticos_angola_raw.geojson\"\n",
    "output_path = DATA_DIR / \"pontos_turisticos_angola_normalizado.geojson\"\n",
    "\n",
    "try:\n",
    "    gdf = gpd.read_file(input_path)\n",
    "    print(f\" Arquivo bruto '{input_path.name}' carregado com {len(gdf)} features.\")\n",
    "except Exception as e:\n",
    "    # Usar 'raise' interrompe a execu√ß√£o se o arquivo base n√£o for encontrado, o que √© o comportamento desejado.\n",
    "    raise RuntimeError(f\"‚ùå ERRO CR√çTICO: N√£o foi poss√≠vel carregar o arquivo de entrada: {e}\")\n",
    "\n",
    "# --- 2. LIMPEZA E DESDUPLICA√á√ÉO ---\n",
    "print(\" Realizando limpeza...\")\n",
    "gdf = gdf[gdf.geometry.notna() & gdf.is_valid]\n",
    "if 'feature_name' in gdf.columns:\n",
    "    gdf = gdf.drop_duplicates(subset=['feature_name', 'geometry'], keep='first')\n",
    "print(f\"  {len(gdf)} features restantes ap√≥s limpeza.\")\n",
    "\n",
    "# --- 3. NORMALIZA√á√ÉO DE CATEGORIAS ---\n",
    "print(\"Normalizando categorias de 'tourism' e 'amenity'...\")\n",
    "\n",
    "# Dicion√°rios de mapeamento para agrupar categorias\n",
    "map_tourism = {\n",
    "    \"guest_house\": \"alojamento\", \"hotel\": \"alojamento\", \"hostel\": \"alojamento\",\n",
    "    \"motel\": \"alojamento\", \"apartment\": \"alojamento\", \"chalet\": \"alojamento\",\n",
    "    \"museum\": \"cultura\", \"artwork\": \"cultura\",\n",
    "    \"attraction\": \"atracao\", \"viewpoint\": \"miradouro\",\n",
    "    \"gallery\": \"arte\", \"zoo\": \"lazer\"\n",
    "}\n",
    "map_amenity = {\n",
    "    \"restaurant\": \"restauracao\", \"fast_food\": \"restauracao\", \"cafe\": \"restauracao\",\n",
    "    \"bar\": \"restauracao\", \"food_court\": \"restauracao\",\n",
    "    \"hospital\": \"saude\", \"clinic\": \"saude\", \"doctors\": \"saude\", \"dentist\": \"saude\",\n",
    "    \"school\": \"educacao\", \"university\": \"educacao\", \"college\": \"educacao\",\n",
    "    \"bank\": \"financeiro\", \"atm\": \"financeiro\", \"bureau_de_change\": \"financeiro\",\n",
    "    \"parking\": \"infraestrutura\", \"bus_station\": \"infraestrutura\", \"taxi\": \"infraestrutura\",\n",
    "    \"ferry_terminal\": \"infraestrutura\"\n",
    "}\n",
    "\n",
    "# Fun√ß√£o segura para aplicar o mapeamento\n",
    "def normalizar_coluna(df, coluna, mapa):\n",
    "    if coluna in df.columns:\n",
    "        # Assegura que a coluna √© do tipo string para usar o .replace\n",
    "        df[coluna] = df[coluna].astype(str).replace(mapa)\n",
    "    return df\n",
    "\n",
    "gdf = normalizar_coluna(gdf, 'tourism', map_tourism)\n",
    "gdf = normalizar_coluna(gdf, 'amenity', map_amenity)\n",
    "print(\" Categorias normalizadas.\")\n",
    "\n",
    "\n",
    "# --- 4. ENGENHARIA DE FEATURES ESPACIAIS ---\n",
    "print(\" Iniciando engenharia de features espaciais (c√°lculos em metros)...\")\n",
    "CRS_METRIC = \"EPSG:32733\" # UTM Zone 33S para Angola\n",
    "gdf_metric = gdf.to_crs(CRS_METRIC)\n",
    "\n",
    "# 4.1. Dist√¢ncia ao vizinho mais pr√≥ximo\n",
    "print(\"   - Calculando dist√¢ncia √† feature mais pr√≥xima...\")\n",
    "centroids = gdf_metric.geometry.centroid\n",
    "coords = np.array(list(zip(centroids.x, centroids.y)))\n",
    "kdtree = cKDTree(coords)\n",
    "# k=2 porque o vizinho mais pr√≥ximo (k=1) √© o pr√≥prio ponto\n",
    "distances, _ = kdtree.query(coords, k=2, workers=-1) # workers=-1 usa todos os cores\n",
    "gdf_metric['dist_nearest_feature_m'] = distances[:, 1]\n",
    "\n",
    "# 4.2. Contagem de features pr√≥ximas (Densidade)\n",
    "print(\"   - Contando features em um raio de 1km...\")\n",
    "BUFFER_RADIUS_M = 1000\n",
    "# sjoin √© uma forma muito mais r√°pida de fazer essa contagem\n",
    "buffers = gdf_metric.geometry.buffer(BUFFER_RADIUS_M)\n",
    "# Contar quantos pontos caem dentro de cada buffer\n",
    "# O resultado de sjoin_counts tem um √≠ndice alinhado com gdf_metric\n",
    "join = gpd.sjoin(gpd.GeoDataFrame(geometry=buffers), gdf_metric, how='left', predicate='contains')\n",
    "counts = join.groupby(join.index).size() - 1 # Subtrai 1 para n√£o contar o pr√≥prio ponto\n",
    "gdf_metric['features_within_1km'] = counts.reindex(gdf_metric.index).fillna(0)\n",
    "\n",
    "print(\"    Vari√°veis espaciais calculadas.\")\n",
    "\n",
    "\n",
    "# --- 5. FINALIZA√á√ÉO E SALVAMENTO ---\n",
    "print(\" Finalizando e salvando o GeoDataFrame enriquecido...\")\n",
    "\n",
    "# Voltar para a proje√ß√£o original (lat/lon)\n",
    "gdf_final = gdf_metric.to_crs(gdf.crs)\n",
    "\n",
    "# Neste ponto, mantemos todas as colunas. A sele√ß√£o final ser√° feita na agrega√ß√£o.\n",
    "gdf_final.to_file(output_path, driver=\"GeoJSON\", encoding='utf-8')\n",
    "\n",
    "print(f\"   Processo conclu√≠do! Arquivo normalizado e enriquecido salvo em: {output_path}\")\n",
    "print(f\"   O arquivo final tem {gdf_final.shape[0]} linhas e {gdf_final.shape[1]} colunas.\")\n",
    "print(\"\\n--- Amostra do Dataset Enriquecido ---\")\n",
    "cols_to_show = [\n",
    "    'ponto_turistico', 'provincia', 'feature_name', 'tourism', 'amenity',\n",
    "    'dist_nearest_feature_m', 'features_within_1km'\n",
    "]\n",
    "existing_cols_to_show = [c for c in cols_to_show if c in gdf_final.columns]\n",
    "display(gdf_final[existing_cols_to_show].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36bcbeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T06:27:50.647739Z",
     "iopub.status.busy": "2025-11-07T06:27:50.647360Z",
     "iopub.status.idle": "2025-11-07T06:27:50.694947Z",
     "shell.execute_reply": "2025-11-07T06:27:50.692917Z"
    },
    "papermill": {
     "duration": 0.058452,
     "end_time": "2025-11-07T06:27:50.696619",
     "exception": false,
     "start_time": "2025-11-07T06:27:50.638167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de mobilidade normalizados salvos em: ..\\data\\climatic-environmental\\mobilidade_infra_normalizado.csv\n",
      "                  nome prov√≠ncia  dist√¢ncia_estrada_principal_(km)  \\\n",
      "0            Ba√≠a Azul  Benguela                               1.2   \n",
      "1           Cristo Rei  Benguela                               0.8   \n",
      "2  Quedas de Kalandula   Malanje                               6.5   \n",
      "3        Serra da Leba     Hu√≠la                               1.0   \n",
      "4     Miradouro da Lua    Luanda                               2.5   \n",
      "\n",
      "   dist√¢ncia_cidade_(km) acessibilidade tipo_via_acesso infraestrutura  \\\n",
      "0                    7.5            Boa     Pavimentada       Completa   \n",
      "1                    5.0            Boa     Pavimentada       Completa   \n",
      "2                   75.0          M√©dia    Terra batida         B√°sica   \n",
      "3                   15.0            Boa     Pavimentada          M√©dia   \n",
      "4                   45.0            Boa     Pavimentada       Completa   \n",
      "\n",
      "           servi√ßos_dispon√≠veis  densidade_populacional_(hab/km¬≤)  \n",
      "0  Energia, telecom, hospedagem                               340  \n",
      "1  Energia, telecom, transporte                               380  \n",
      "2      Energia parcial, turismo                                95  \n",
      "3              Telecom, energia                               120  \n",
      "4              Energia, telecom                               430  \n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# NORMALIZA√á√ÉO DOS DADOS DE MOBILIDADE E DE INFRAESTRUTURA\n",
    "# ==============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# === Diret√≥rio e arquivo ===\n",
    "DATA_DIR = Path(\"../data/climatic-environmental\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "input_path = DATA_DIR / \"mobilidade_infra.csv\"\n",
    "\n",
    "# === Carregar ===\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# === Normalizar nomes de colunas ===\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(r'\\s+', '_', regex=True)\n",
    "\n",
    "# === Preenchimento b√°sico ===\n",
    "num_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "for c in num_cols:\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].fillna(\"desconhecido\")\n",
    "\n",
    "# === Limites plaus√≠veis ===\n",
    "if \"velocidade_media_kmh\" in df.columns:\n",
    "    df[\"velocidade_media_kmh\"] = df[\"velocidade_media_kmh\"].clip(lower=0, upper=200)\n",
    "\n",
    "if \"capacidade\" in df.columns:\n",
    "    df[\"capacidade\"] = df[\"capacidade\"].clip(lower=0)\n",
    "\n",
    "if \"fluxo_diario\" in df.columns:\n",
    "    df[\"fluxo_diario\"] = df[\"fluxo_diario\"].clip(lower=0)\n",
    "\n",
    "# === Datas ===\n",
    "for date_col in [\"date\", \"data\", \"timestamp\"]:\n",
    "    if date_col in df.columns:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "\n",
    "# === Normalizar categorias de infraestrutura ===\n",
    "infra_col_candidates = [c for c in df.columns if c in (\"tipo\", \"tipo_infra\", \"infra_type\", \"category\")]\n",
    "if infra_col_candidates:\n",
    "    infra_col = infra_col_candidates[0]\n",
    "    df[infra_col] = df[infra_col].astype(str).str.lower()\n",
    "    df[\"is_road\"] = df[infra_col].str.contains(r\"road|highway|estrada\", na=False).astype(int)\n",
    "    df[\"is_rail\"] = df[infra_col].str.contains(r\"rail|ferrovia\", na=False).astype(int)\n",
    "    df[\"is_port\"] = df[infra_col].str.contains(r\"port|porto\", na=False).astype(int)\n",
    "    df[\"is_airport\"] = df[infra_col].str.contains(r\"airport|aeroporto\", na=False).astype(int)\n",
    "\n",
    "# === Coordenadas -> GeoDataFrame ===\n",
    "lat_candidates = [c for c in df.columns if c in (\"latitude\", \"lat\", \"y\")]\n",
    "lon_candidates = [c for c in df.columns if c in (\"longitude\", \"lon\", \"lng\", \"x\")]\n",
    "\n",
    "output_csv = DATA_DIR / \"mobilidade_infra_normalizado.csv\"\n",
    "output_geo = DATA_DIR / \"mobilidade_infra_normalizado.geojson\"\n",
    "\n",
    "if lat_candidates and lon_candidates:\n",
    "    lat_col = lat_candidates[0]\n",
    "    lon_col = lon_candidates[0]\n",
    "    df = df.dropna(subset=[lat_col, lon_col])\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df.copy(),\n",
    "        geometry=gpd.points_from_xy(df[lon_col].astype(float), df[lat_col].astype(float)),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    gdf.to_file(output_geo, driver=\"GeoJSON\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Dados de mobilidade normalizados salvos em:\\n   - {output_csv}\\n   - {output_geo}\")\n",
    "else:\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Dados de mobilidade normalizados salvos em: {output_csv}\")\n",
    "    print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c491642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T06:27:50.710357Z",
     "iopub.status.busy": "2025-11-07T06:27:50.709983Z",
     "iopub.status.idle": "2025-11-07T06:27:50.740470Z",
     "shell.execute_reply": "2025-11-07T06:27:50.737909Z"
    },
    "papermill": {
     "duration": 0.040224,
     "end_time": "2025-11-07T06:27:50.742629",
     "exception": false,
     "start_time": "2025-11-07T06:27:50.702405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados clim√°ticos-ambientais normalizados salvos em: ..\\data\\climatic-environmental\\clima_lulc_normalizado.csv\n",
      "  nome_ponto_turistico provincia  temp_med_anual  precipitacao_anual  NDVI  \\\n",
      "0  Quedas de Calandula   Malanje            26.3                1290  0.72   \n",
      "1     Miradouro da Lua    Luanda            27.8                 320  0.26   \n",
      "2    Parque da Kissama    Luanda            26.9                 310  0.33   \n",
      "3            Baia Azul  Benguela            27.1                 280  0.05   \n",
      "4    Reserva do Namibe    Namibe            28.5                  90  0.02   \n",
      "\n",
      "    EVI  NDWI LULC_codigo  altitude  \n",
      "0  0.64  0.09          20      1058  \n",
      "1  0.18  0.12          60       112  \n",
      "2  0.25  0.07          30       180  \n",
      "3  0.11  0.04          60        12  \n",
      "4  0.08  0.01          60        60  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ==============================================================\n",
    "# NORMALIZA√á√ÉO DOS DADOS CLIMATICOS-AMBIENTAIS\n",
    "\n",
    "# ==============================================================\n",
    "# === Diret√≥rio e arquivos ===\n",
    "DATA_DIR = Path(\"../data/climatic-environmental\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "input_clima = DATA_DIR / \"1clima_lulc.csv\"\n",
    "df_clima = pd.read_csv(input_clima)\n",
    "\n",
    "# === Normaliza√ß√£o dos dados ===\n",
    "# Temperatura m√©dia anual (¬∞C)\n",
    "df_clima['temp_med_anual'] = df_clima['temp_med_anual'].clip(20, 35)\n",
    "\n",
    "# Precipita√ß√£o anual (mm)\n",
    "df_clima['precipitacao_anual'] = df_clima['precipitacao_anual'].clip(0, 2000)\n",
    "\n",
    "# √çndices de vegeta√ß√£o e √°gua\n",
    "for col in ['NDVI', 'EVI', 'NDWI']:\n",
    "    df_clima[col] = df_clima[col].clip(-1, 1)\n",
    "\n",
    "# C√≥digos LULC (Land Use Land Cover)\n",
    "df_clima['LULC_codigo'] = df_clima['LULC_codigo'].astype('category')\n",
    "\n",
    "# Altitude (m)\n",
    "df_clima['altitude'] = df_clima['altitude'].clip(0, 2500)\n",
    "\n",
    "# === Salvar dados normalizados ===\n",
    "output_path = DATA_DIR / \"clima_lulc_normalizado.csv\"\n",
    "df_clima.to_csv(output_path, index=False)\n",
    "print(f\" Dados clim√°ticos-ambientais normalizados salvos em: {output_path}\")\n",
    "print(df_clima.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f57fb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T06:27:50.756469Z",
     "iopub.status.busy": "2025-11-07T06:27:50.755896Z",
     "iopub.status.idle": "2025-11-07T06:27:50.784120Z",
     "shell.execute_reply": "2025-11-07T06:27:50.782311Z"
    },
    "papermill": {
     "duration": 0.03808,
     "end_time": "2025-11-07T06:27:50.786596",
     "exception": false,
     "start_time": "2025-11-07T06:27:50.748516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dados econ√¥micos-sociais normalizados salvos em: ..\\data\\economicsocial\\economicsocial_normalizado.csv\n",
      "                        nome provincia  populacao  densidade_pop  \\\n",
      "0        Quedas de Calandula   Malanje     129958           77.1   \n",
      "1           Miradouro da Lua    Luanda     154867          298.1   \n",
      "2           Museu Kulumbimbi     Zaire     139932           39.5   \n",
      "3  Reserva Parcial do Namibe    Namibe     111694          329.1   \n",
      "4    Fortaleza de S√£o Miguel    Luanda     127879          423.3   \n",
      "\n",
      "   pib_per_capita    idh  taxa_urbanizacao  emprego_turismo  \n",
      "0         1898.31  0.522              80.6              3.2  \n",
      "1         1471.82  0.655              68.6              8.1  \n",
      "2         3055.16  0.633              44.6              7.7  \n",
      "3         2347.39  0.700              59.2              6.5  \n",
      "4         4149.69  0.502              56.3              3.2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ==============================================================\n",
    "# NORMALIZA√á√ÉO DOS DADOS ECON√îMICOS-SOCIAIS\n",
    "# ==============================================================\n",
    "# === Diret√≥rio e arquivos ===\n",
    "DATA_DIR = Path(\"../data/economicsocial\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "input_eco = DATA_DIR / \"dados_socioeconomicos.csv\"\n",
    "df_eco = pd.read_csv(input_eco)\n",
    "\n",
    "# === Normaliza√ß√£o dos dados ===\n",
    "# PIB per capita \n",
    "df_eco['pib_per_capita'] = df_eco['pib_per_capita'].clip(500, 5000)\n",
    "\n",
    "# Popula√ß√£o\n",
    "df_eco['populacao'] = df_eco['populacao'].clip(1000, 1000000)\n",
    "\n",
    "# √çndice de desenvolvimento humano\n",
    "df_eco['idh'] = df_eco['idh'].clip(0, 1)\n",
    "\n",
    "# Densidade populacional (hab/km¬≤)\n",
    "df_eco['densidade_pop'] = df_eco['densidade_pop'].clip(0, 1000)\n",
    "\n",
    "# Taxa de urbaniza√ß√£o (%)\n",
    "df_eco['taxa_urbanizacao'] = df_eco['taxa_urbanizacao'].clip(0, 100)\n",
    "\n",
    "# === Salvar dados normalizados ===\n",
    "output_path = DATA_DIR / \"economicsocial_normalizado.csv\"\n",
    "df_eco.to_csv(output_path, index=False)\n",
    "print(f\" Dados econ√¥micos-sociais normalizados salvos em: {output_path}\")\n",
    "print(df_eco.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b056fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T06:27:50.800314Z",
     "iopub.status.busy": "2025-11-07T06:27:50.799933Z",
     "iopub.status.idle": "2025-11-07T06:28:07.731012Z",
     "shell.execute_reply": "2025-11-07T06:28:07.728456Z"
    },
    "papermill": {
     "duration": 16.940717,
     "end_time": "2025-11-07T06:28:07.732529",
     "exception": false,
     "start_time": "2025-11-07T06:27:50.791812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados brutos para enriquecimento...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Arquivo 'pontos_turisticos_angola_raw.geojson' carregado com 1719 features.\n",
      "Proje√ß√£o convertida para EPSG:32733 para c√°lculos em metros.\n",
      "Calculando a dist√¢ncia ao vizinho mais pr√≥ximo...\n",
      "Contando features dentro de um raio de 1km...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando a proximidade a categorias espec√≠ficas...\n",
      "Finalizando e salvando o resultado...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processo de gera√ß√£o de vari√°veis espaciais conclu√≠do!\n",
      " Arquivo enriquecido salvo em: ..\\data\\geoespacial\\pontos_turisticos_angola_normalizado.geojson\n",
      "\n",
      "--- Amostra do Dataset Enriquecido ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ponto_turistico</th>\n",
       "      <th>provincia</th>\n",
       "      <th>tourism</th>\n",
       "      <th>amenity</th>\n",
       "      <th>leisure</th>\n",
       "      <th>natural</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>dist_nearest_feature_m</th>\n",
       "      <th>features_within_1km</th>\n",
       "      <th>hospital_nearby_1km</th>\n",
       "      <th>school_nearby_1km</th>\n",
       "      <th>restaurant_nearby_1km</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>83.325233</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (16.00032 -9.07407)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>48.478089</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (15.9989 -9.07401)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>113.281622</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (16.00249 -9.07421)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>camp_site</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>27.721497</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (16.00206 -9.078)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quedas de Calandula</td>\n",
       "      <td>Malanje</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2375.771517</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINESTRING (15.97131 -9.12829, 15.97187 -9.127...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ponto_turistico provincia    tourism amenity leisure natural latitude  \\\n",
       "0  Quedas de Calandula   Malanje       None    None    None    None     None   \n",
       "1  Quedas de Calandula   Malanje       None    None    None    None     None   \n",
       "2  Quedas de Calandula   Malanje       None    None    None    None     None   \n",
       "3  Quedas de Calandula   Malanje  camp_site    None    None    None     None   \n",
       "4  Quedas de Calandula   Malanje       None    None    None    None     None   \n",
       "\n",
       "  longitude  dist_nearest_feature_m  features_within_1km  hospital_nearby_1km  \\\n",
       "0      None               83.325233                   28                    0   \n",
       "1      None               48.478089                   28                    0   \n",
       "2      None              113.281622                   29                    0   \n",
       "3      None               27.721497                   29                    0   \n",
       "4      None             2375.771517                    5                    0   \n",
       "\n",
       "   school_nearby_1km  restaurant_nearby_1km  \\\n",
       "0                  0                      1   \n",
       "1                  0                      1   \n",
       "2                  0                      1   \n",
       "3                  0                      1   \n",
       "4                  0                      0   \n",
       "\n",
       "                                            geometry  \n",
       "0                          POINT (16.00032 -9.07407)  \n",
       "1                           POINT (15.9989 -9.07401)  \n",
       "2                          POINT (16.00249 -9.07421)  \n",
       "3                            POINT (16.00206 -9.078)  \n",
       "4  LINESTRING (15.97131 -9.12829, 15.97187 -9.127...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# SCRIPT DE GERA√á√ÉO DE VARI√ÅVEIS ESPACIAIS - VERS√ÉO OTIMIZADA\n",
    "# ====================================================================\n",
    "\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. CONFIGURA√á√ÉO DE CAMINHOS ---\n",
    "DATA_DIR = Path(\"../data/geoespacial\")\n",
    "# Usamos o _raw como entrada, pois ele cont√©m todas as features\n",
    "input_path = DATA_DIR / \"pontos_turisticos_angola_raw.geojson\" \n",
    "# A sa√≠da ser√° o _normalizado, agora enriquecido com vari√°veis espaciais\n",
    "output_path = DATA_DIR / \"pontos_turisticos_angola_normalizado.geojson\" \n",
    "\n",
    "print(\"Carregando dados brutos para enriquecimento...\")\n",
    "try:\n",
    "    gdf = gpd.read_file(input_path)\n",
    "    print(f\" Arquivo '{input_path.name}' carregado com {len(gdf)} features.\")\n",
    "except Exception as e:\n",
    "    print(f\"üö® ERRO CR√çTICO: N√£o foi poss√≠vel carregar o arquivo de entrada: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. PREPARA√á√ÉO DO GEODATAFRAME ---\n",
    "# Converter para uma proje√ß√£o m√©trica (em metros) para c√°lculos precisos\n",
    "CRS_METRIC = \"EPSG:32733\" # UTM Zone 33S para Angola\n",
    "gdf_metric = gdf.to_crs(CRS_METRIC)\n",
    "print(f\"Proje√ß√£o convertida para {CRS_METRIC} para c√°lculos em metros.\")\n",
    "\n",
    "\n",
    "# --- 3. C√ÅLCULO DE DIST√ÇNCIA AO VIZINHO MAIS PR√ìXIMO  ---\n",
    "print(\"Calculando a dist√¢ncia ao vizinho mais pr√≥ximo...\")\n",
    "\n",
    "# Usar o centroide garante que funcione para pontos, linhas e pol√≠gonos\n",
    "centroids = gdf_metric.geometry.centroid\n",
    "coords = np.array(list(zip(centroids.x, centroids.y)))\n",
    "\n",
    "# Construir a √°rvore espacial para busca r√°pida\n",
    "kdtree = cKDTree(coords)\n",
    "\n",
    "# Encontrar o segundo vizinho mais pr√≥ximo (o primeiro √© o pr√≥prio ponto)\n",
    "distances, _ = kdtree.query(coords, k=2)\n",
    "nearest_distances = distances[:, 1]\n",
    "\n",
    "# Adicionar a nova coluna ao GeoDataFrame\n",
    "gdf_metric['dist_nearest_feature_m'] = nearest_distances\n",
    "\n",
    "\n",
    "# --- 4. CONTAGEM DE FEATURES PR√ìXIMAS (DENSIDADE - OTIMIZADO) ---\n",
    "print(\"Contando features dentro de um raio de 1km...\")\n",
    "BUFFER_RADIUS_M = 1000\n",
    "\n",
    "# Usar o √≠ndice espacial para uma contagem eficiente\n",
    "spatial_index = gdf_metric.sindex\n",
    "counts = []\n",
    "for i, row in gdf_metric.iterrows():\n",
    "    buffer = row.geometry.buffer(BUFFER_RADIUS_M)\n",
    "    possible_matches_index = list(spatial_index.intersection(buffer.bounds))\n",
    "    precise_matches = gdf_metric.iloc[possible_matches_index]\n",
    "    points_within = precise_matches[precise_matches.geometry.within(buffer)]\n",
    "    counts.append(len(points_within) - 1)\n",
    "\n",
    "gdf_metric['features_within_1km'] = counts\n",
    "\n",
    "\n",
    "# --- 5. FLAG DE PROXIMIDADE A CATEGORIAS (OTIMIZADO) ---\n",
    "print(\"Verificando a proximidade a categorias espec√≠ficas...\")\n",
    "\n",
    "# Filtrar para criar GeoDataFrames para cada categoria de interesse\n",
    "hospitais = gdf_metric[gdf_metric['amenity'] == 'hospital'].copy()\n",
    "escolas = gdf_metric[gdf_metric['amenity'] == 'school'].copy()\n",
    "restaurantes = gdf_metric[gdf_metric['amenity'] == 'restaurant'].copy()\n",
    "\n",
    "# Fun√ß√£o otimizada para criar a flag de proximidade\n",
    "def criar_flag_proximidade(gdf_base, gdf_alvo, nome_coluna, raio_m=1000):\n",
    "    if not gdf_alvo.empty:\n",
    "        join_prox = gpd.sjoin_nearest(gdf_base, gdf_alvo, distance_col=\"distancia\")\n",
    "        distancias_df = join_prox[['distancia']]\n",
    "        distancias_df = distancias_df[~distancias_df.index.duplicated(keep='first')]\n",
    "        flag_series = (distancias_df['distancia'] <= raio_m)\n",
    "        gdf_base[nome_coluna] = flag_series.reindex(gdf_base.index).fillna(False).astype(int)\n",
    "    else:\n",
    "        gdf_base[nome_coluna] = 0\n",
    "    return gdf_base\n",
    "\n",
    "# Aplicar a fun√ß√£o para cada categoria\n",
    "gdf_metric = criar_flag_proximidade(gdf_metric, hospitais, 'hospital_nearby_1km')\n",
    "gdf_metric = criar_flag_proximidade(gdf_metric, escolas, 'school_nearby_1km')\n",
    "gdf_metric = criar_flag_proximidade(gdf_metric, restaurantes, 'restaurant_nearby_1km')\n",
    "\n",
    "\n",
    "# --- 6. FINALIZA√á√ÉO E SALVAMENTO ---\n",
    "print(\"Finalizando e salvando o resultado...\")\n",
    "\n",
    "# Voltar para a proje√ß√£o original (lat/lon)\n",
    "gdf_final = gdf_metric.to_crs(gdf.crs)\n",
    "\n",
    "# Selecionar um conjunto final de colunas para manter o arquivo limpo\n",
    "colunas_finais = [\n",
    "    'ponto_turistico', 'provincia', 'tourism', 'amenity', \n",
    "    'leisure', 'natural', 'latitude', 'longitude', \n",
    "    'dist_nearest_feature_m', 'features_within_1km',\n",
    "    'hospital_nearby_1km', 'school_nearby_1km', 'restaurant_nearby_1km',\n",
    "    'geometry'\n",
    "]\n",
    "colunas_existentes = [col for col in colunas_finais if col in gdf_final.columns]\n",
    "gdf_final_limpo = gdf_final[colunas_existentes]\n",
    "\n",
    "\n",
    "# Salvar no arquivo de sa√≠da\n",
    "gdf_final_limpo.to_file(output_path, driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"\\n Processo de gera√ß√£o de vari√°veis espaciais conclu√≠do!\")\n",
    "print(f\" Arquivo enriquecido salvo em: {output_path}\")\n",
    "print(\"\\n--- Amostra do Dataset Enriquecido ---\")\n",
    "display(gdf_final_limpo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6845c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T06:28:07.753093Z",
     "iopub.status.busy": "2025-11-07T06:28:07.752203Z",
     "iopub.status.idle": "2025-11-07T06:28:08.130129Z",
     "shell.execute_reply": "2025-11-07T06:28:08.128456Z"
    },
    "papermill": {
     "duration": 0.392031,
     "end_time": "2025-11-07T06:28:08.131931",
     "exception": false,
     "start_time": "2025-11-07T06:28:07.739900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iniciando a integra√ß√£o final de todas as fontes de dados...\n",
      "\n",
      " Carregando e preparando as fontes de dados...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Socioecon√¥mico: Arquivo carregado. Chave criada a partir de 'nome'.\n",
      " Mobilidade: Arquivo carregado. Chave criada a partir de 'nome'.\n",
      "\n",
      " Agregando features geoespaciais por ponto tur√≠stico...\n",
      " Processo interrompido. Arquivo geoespacial base n√£o p√¥de ser carregado.\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# C√âLULA FINAL: INTEGRA√á√ÉO E AGREGA√á√ÉO PARA GERAR model_input.csv\n",
    "# ====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\" Iniciando a integra√ß√£o final de todas as fontes de dados...\")\n",
    "\n",
    "# --- 1. FUN√á√ïES AUXILIARES (sem altera√ß√µes) ---\n",
    "\n",
    "def normalizar_texto(texto):\n",
    "    \"\"\"Fun√ß√£o robusta para limpar e padronizar textos para jun√ß√£o.\"\"\"\n",
    "    if pd.isna(texto): return \"\"\n",
    "    texto = str(texto).strip().lower()\n",
    "    texto = re.sub(r\"[√°√†√£√¢√§]\", \"a\", texto); texto = re.sub(r\"[√©√®√™√´]\", \"e\", texto)\n",
    "    texto = re.sub(r\"[√≠√¨√Æ√Ø]\", \"i\", texto); texto = re.sub(r\"[√≥√≤√µ√¥√∂]\", \"o\", texto)\n",
    "    texto = re.sub(r\"[√∫√π√ª√º]\", \"u\", texto); texto = re.sub(r\"√ß\", \"c\", texto)\n",
    "    texto = re.sub(r\"[^a-z0-9_]\", \"\", texto) # Permite underscore\n",
    "    return texto\n",
    "\n",
    "def carregar_e_preparar(caminho, chaves_possiveis, nome_df=\"\", is_geo=False):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o unificada para carregar, normalizar colunas e criar a chave de jun√ß√£o.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = gpd.read_file(caminho) if is_geo else pd.read_csv(caminho, encoding='utf-8')\n",
    "        df.columns = [normalizar_texto(c) for c in df.columns]\n",
    "        coluna_chave = next((col for col in chaves_possiveis if col in df.columns), None)\n",
    "        \n",
    "        if coluna_chave:\n",
    "            df['key'] = df[coluna_chave].astype(str).apply(lambda x: normalizar_texto(x.replace('_', '')))\n",
    "            print(f\" {nome_df}: Arquivo carregado. Chave criada a partir de '{coluna_chave}'.\")\n",
    "            return df\n",
    "        else:\n",
    "            warnings.warn(f\" Nenhuma coluna chave encontrada para '{nome_df}'.\")\n",
    "            return gpd.GeoDataFrame() if is_geo else pd.DataFrame()\n",
    "            \n",
    "    except Exception as e:\n",
    "        warnings.warn(f\" N√£o foi poss√≠vel carregar ou processar o arquivo para '{nome_df}': {e}\")\n",
    "        return gpd.GeoDataFrame() if is_geo else pd.DataFrame()\n",
    "\n",
    "# --- 2. CONFIGURA√á√ÉO DE CAMINHOS E CARREGAMENTO ---\n",
    "BASE_DIR = Path(\"../data\")\n",
    "PATH_GEO_NORM = BASE_DIR / \"geoespacial/pontos_turisticos_angola_normalizado.geojson\"\n",
    "PATH_CLIMA = BASE_DIR / \"climatic-environmental/clima_lulc_normalizado.csv\"\n",
    "PATH_SOCIO = BASE_DIR / \"economicsocial/economicsocial_normalizado.csv\"\n",
    "PATH_MOB = BASE_DIR / \"climatic-environmental/mobilidade_infra_normalizado.csv\"\n",
    "OUTPUT_PATH = BASE_DIR / \"model_inputs/model_input.csv\"\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\n Carregando e preparando as fontes de dados...\")\n",
    "\n",
    "chaves_geo = [\"pontoturistico\"]\n",
    "chaves_clima = [\"nomepontoturistico\"]\n",
    "chaves_socio = [\"poinome\", \"nome\"]\n",
    "chaves_mob = [\"nome\", \"poinome\"]\n",
    "\n",
    "gdf_norm = carregar_e_preparar(PATH_GEO_NORM, chaves_geo, \"Geo Normalizado\", is_geo=True)\n",
    "df_clima = carregar_e_preparar(PATH_CLIMA, chaves_clima, \"Clima\")\n",
    "df_socio = carregar_e_preparar(PATH_SOCIO, chaves_socio, \"Socioecon√¥mico\")\n",
    "df_mob = carregar_e_preparar(PATH_MOB, chaves_mob, \"Mobilidade\")\n",
    "\n",
    "# --- 3. AGREGA√á√ÉO DO DATAFRAME GEOESPACIAL ---\n",
    "print(\"\\n Agregando features geoespaciais por ponto tur√≠stico...\")\n",
    "if not gdf_norm.empty:\n",
    "    # 3.1. Criar a base com informa√ß√µes √∫nicas (uma linha por ponto tur√≠stico)\n",
    "    df_base = gdf_norm[['pontoturistico', 'provincia', 'poilat', 'poilon', 'key']].drop_duplicates(subset='key').reset_index(drop=True)\n",
    "\n",
    "    # 3.2. Agrega√ß√£o Num√©rica: Calcular estat√≠sticas das features espaciais\n",
    "    features_numericas = ['distnearestfeaturem', 'featureswithin1km']\n",
    "    existing_numeric = [c for c in features_numericas if c in gdf_norm.columns]\n",
    "    \n",
    "    if existing_numeric:\n",
    "        agg_numeric = gdf_norm.groupby('key')[existing_numeric].agg(['mean', 'std', 'max']).reset_index()\n",
    "        agg_numeric.columns = ['_'.join(col).strip() for col in agg_numeric.columns.values]\n",
    "        agg_numeric = agg_numeric.rename(columns={'key_': 'key'})\n",
    "        print(f\"  Features num√©ricas agregadas: {agg_numeric.shape[1]-1} novas colunas.\")\n",
    "    else:\n",
    "        agg_numeric = pd.DataFrame({'key': df_base['key']}) # Cria df vazio com a key\n",
    "        print(\"Nenhuma feature num√©rica para agregar.\")\n",
    "\n",
    "    # 3.3. Agrega√ß√£o Categ√≥rica: Contar a ocorr√™ncia de cada tipo de feature\n",
    "    features_categoricas = ['tourism', 'amenity', 'leisure', 'natural', 'landuse', 'highway']\n",
    "    existing_categorical = [c for c in features_categoricas if c in gdf_norm.columns]\n",
    "    \n",
    "    if existing_categorical:\n",
    "        dummies = pd.get_dummies(gdf_norm[['key'] + existing_categorical], columns=existing_categorical, prefix_sep='_')\n",
    "        agg_categorical = dummies.groupby('key').sum().reset_index()\n",
    "        print(f\"Features categ√≥ricas agregadas: {agg_categorical.shape[1]-1} novas colunas.\")\n",
    "    else:\n",
    "        agg_categorical = pd.DataFrame({'key': df_base['key']}) # Cria df vazio com a key\n",
    "        print(\" Nenhuma feature categ√≥rica para agregar.\")\n",
    "\n",
    "    # --- 4. JUN√á√ÉO (MERGE) DE TODOS OS DATASETS ---\n",
    "    print(\"\\n Juntando todos os datasets em uma √∫nica tabela...\")\n",
    "    \n",
    "    # Come√ßar com a base e juntar as agrega√ß√µes\n",
    "    df_final = pd.merge(df_base, agg_numeric, on='key', how='left')\n",
    "    df_final = pd.merge(df_final, agg_categorical, on='key', how='left')\n",
    "\n",
    "    # Juntar os outros datasets (clima, socio, mob)\n",
    "    if not df_clima.empty:\n",
    "        df_final = pd.merge(df_final, df_clima.drop(columns=[c for c in ['provincia'] if c in df_clima.columns], errors='ignore'), on=\"key\", how=\"left\")\n",
    "    if not df_socio.empty:\n",
    "        df_final = pd.merge(df_final, df_socio.drop(columns=[c for c in ['provincia'] if c in df_socio.columns], errors='ignore'), on=\"key\", how=\"left\", suffixes=(\"\", \"_socio\"))\n",
    "    if not df_mob.empty:\n",
    "        df_final = pd.merge(df_final, df_mob, on=\"key\", how=\"left\", suffixes=(\"\", \"_mob\"))\n",
    "\n",
    "    # --- 5. LIMPEZA FINAL ---\n",
    "    print(\"\\n Realizando limpeza final...\")\n",
    "    df_final = df_final.rename(columns={'pontoturistico': 'poi_nome', 'poilat': 'latitude', 'poilon': 'longitude'})\n",
    "    \n",
    "    # Remover colunas duplicadas de merges e a chave\n",
    "    cols_to_drop = [c for c in df_final.columns if c.endswith(('_socio', '_mob'))]\n",
    "    cols_to_drop += ['key']\n",
    "    # Remover colunas de nome originais dos datasets mergeados\n",
    "    cols_to_drop += ['nomepontoturistico', 'poinome', 'nome']\n",
    "    \n",
    "    df_final = df_final.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # Preencher valores nulos restantes. 0 √© uma escolha simples, mas pode n√£o ser a ideal para todas as colunas.\n",
    "    df_final = df_final.fillna(0)\n",
    "\n",
    "    # --- 6. SALVAR CSV FINAL ---\n",
    "    df_final.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"\\n Processo conclu√≠do! O dataset final tem {df_final.shape[0]} linhas e {df_final.shape[1]} colunas.\")\n",
    "    print(f\"   Model Input salvo em: {OUTPUT_PATH}\")\n",
    "    print(\"\\n--- Amostra do Dataset Final ---\")\n",
    "    display(df_final.head())\n",
    "else:\n",
    "    print(\" Processo interrompido. Arquivo geoespacial base n√£o p√¥de ser carregado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmbienteVirtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 85.139558,
   "end_time": "2025-11-07T06:28:09.138654",
   "environment_variables": {},
   "exception": null,
   "input_path": "C:\\MapaTurismo\\notebooks\\data_preparation.ipynb",
   "output_path": "C:\\MapaTurismo\\notebooks_executed\\data_preparation.ipynb",
   "parameters": {},
   "start_time": "2025-11-07T06:26:43.999096",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}